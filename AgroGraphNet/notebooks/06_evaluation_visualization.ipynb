{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgroGraphNet: Evaluation and Visualization\n",
    "\n",
    "This notebook provides comprehensive evaluation and visualization of the trained models.\n",
    "\n",
    "## Objectives:\n",
    "1. Load trained models and results\n",
    "2. Create detailed performance visualizations\n",
    "3. Generate spatial prediction maps\n",
    "4. Analyze model interpretability and feature importance\n",
    "5. Create disease spread animations\n",
    "6. Generate comprehensive dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import DataLoader\n",
    "import folium\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pickle\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from config import *\n",
    "from model_utils import *\n",
    "from visualization import *\n",
    "from graph_utils import *\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model results and data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Ash09\\\\agro_tech\\\\AgroGraphNet\\\\notebooks\\\\..\\\\results\\\\model_results.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading model results and data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load model results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRESULTS_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel_results.pkl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      6\u001b[39m     results_data = pickle.load(f)\n\u001b[32m      8\u001b[39m baseline_results = results_data[\u001b[33m'\u001b[39m\u001b[33mbaseline_results\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\agro_tech\\agro_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Ash09\\\\agro_tech\\\\AgroGraphNet\\\\notebooks\\\\..\\\\results\\\\model_results.pkl'"
     ]
    }
   ],
   "source": [
    "# Load model results and data\n",
    "print(\"Loading model results and data...\")\n",
    "\n",
    "# Load model results\n",
    "with open(RESULTS_DIR / 'model_results.pkl', 'rb') as f:\n",
    "    results_data = pickle.load(f)\n",
    "\n",
    "baseline_results = results_data['baseline_results']\n",
    "gnn_results = results_data['gnn_results']\n",
    "best_model_name = results_data['best_model_name']\n",
    "best_model_accuracy = results_data['best_model_accuracy']\n",
    "model_comparison = results_data['model_comparison']\n",
    "\n",
    "print(f\"✅ Loaded model results\")\n",
    "print(f\"Best model: {best_model_name} (Accuracy: {best_model_accuracy:.4f})\")\n",
    "\n",
    "# Load graph data\n",
    "with open(PROCESSED_DATA_DIR / 'pytorch_graphs.pkl', 'rb') as f:\n",
    "    graph_data = pickle.load(f)\n",
    "\n",
    "graphs = graph_data['graphs']\n",
    "train_indices = graph_data['train_indices']\n",
    "val_indices = graph_data['val_indices']\n",
    "test_indices = graph_data['test_indices']\n",
    "time_points = graph_data['time_points']\n",
    "\n",
    "print(f\"✅ Loaded graph data: {len(graphs)} graphs\")\n",
    "\n",
    "# Load farm locations\n",
    "farm_files = list(FARM_LOCATIONS_DIR.glob('*.csv'))\n",
    "farms_df = pd.read_csv(farm_files[0])\n",
    "\n",
    "# Load final features for additional analysis\n",
    "final_features = pd.read_csv(PROCESSED_DATA_DIR / 'final_features.csv')\n",
    "final_features['date'] = pd.to_datetime(final_features['date'])\n",
    "\n",
    "print(f\"✅ Loaded farm data: {len(farms_df)} farms\")\n",
    "print(f\"✅ Loaded feature data: {final_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model performance analysis\n",
    "print(\"Creating comprehensive performance analysis...\")\n",
    "\n",
    "# Get best GNN results\n",
    "best_gnn_results = gnn_results[best_model_name]\n",
    "\n",
    "# Create comprehensive dashboard\n",
    "dashboard_results = {\n",
    "    'train_losses': best_gnn_results.get('train_losses', []),\n",
    "    'val_accuracies': best_gnn_results.get('val_accuracies', []),\n",
    "    'test_accuracy': best_gnn_results['test_accuracy'],\n",
    "    'best_val_accuracy': best_gnn_results.get('best_val_accuracy', 0),\n",
    "    'confusion_matrix': best_gnn_results.get('confusion_matrix', np.array([])),\n",
    "    'classification_report': best_gnn_results.get('classification_report', {}),\n",
    "    'model_comparison': {name: data['test_accuracy'] for name, data in baseline_results.items()}\n",
    "}\n",
    "\n",
    "# Add GNN results to comparison\n",
    "for name, data in gnn_results.items():\n",
    "    dashboard_results['model_comparison'][name] = data['test_accuracy']\n",
    "\n",
    "# Create dashboard\n",
    "fig = create_dashboard_summary(\n",
    "    dashboard_results,\n",
    "    save_path=str(RESULTS_DIR / '06_comprehensive_dashboard.png')\n",
    ")\n",
    "\n",
    "print(\"✅ Comprehensive dashboard created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spatial Prediction Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial prediction maps\n",
    "print(\"Creating spatial prediction maps...\")\n",
    "\n",
    "# Load the best trained model\n",
    "best_model_path = MODELS_DIR / f'best_{best_model_name.lower()}_model.pth'\n",
    "\n",
    "if best_model_path.exists():\n",
    "    # Recreate model architecture\n",
    "    input_dim = graphs[0].x.shape[1]\n",
    "    hidden_dim = MODEL_CONFIG['hidden_dim']\n",
    "    output_dim = len(DISEASE_CLASSES)\n",
    "    num_layers = MODEL_CONFIG['num_layers']\n",
    "    dropout = MODEL_CONFIG['dropout']\n",
    "    \n",
    "    if best_model_name == 'GCN':\n",
    "        model = GCNModel(input_dim, hidden_dim, output_dim, num_layers, dropout)\n",
    "    elif best_model_name == 'GraphSAGE':\n",
    "        model = GraphSAGEModel(input_dim, hidden_dim, output_dim, num_layers, dropout)\n",
    "    elif best_model_name == 'GAT':\n",
    "        model = GATModel(input_dim, hidden_dim, output_dim, num_layers, dropout)\n",
    "    \n",
    "    # Load trained weights\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"✅ Loaded trained {best_model_name} model\")\n",
    "    \n",
    "    # Make predictions on test graphs\n",
    "    test_graphs = [graphs[i] for i in test_indices]\n",
    "    test_loader = DataLoader(test_graphs, batch_size=1, shuffle=False)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch.x, batch.edge_index, batch.batch)\n",
    "            \n",
    "            # Get predictions and probabilities\n",
    "            pred = out.argmax(dim=1)\n",
    "            prob = torch.softmax(out, dim=1)\n",
    "            \n",
    "            all_predictions.extend(pred.cpu().numpy())\n",
    "            all_true_labels.extend(batch.y.cpu().numpy())\n",
    "            all_probabilities.extend(prob.cpu().numpy())\n",
    "    \n",
    "    print(f\"✅ Generated predictions for {len(all_predictions)} samples\")\n",
    "    \n",
    "    # Create prediction DataFrame\n",
    "    test_time_points = [time_points[i] for i in test_indices]\n",
    "    \n",
    "    prediction_data = []\n",
    "    sample_idx = 0\n",
    "    \n",
    "    for time_idx, time_point in enumerate(test_time_points):\n",
    "        for farm_idx, farm in farms_df.iterrows():\n",
    "            prediction_data.append({\n",
    "                'farm_id': farm['farm_id'],\n",
    "                'lat': farm['lat'],\n",
    "                'lon': farm['lon'],\n",
    "                'date': time_point,\n",
    "                'true_label': all_true_labels[sample_idx],\n",
    "                'predicted_label': all_predictions[sample_idx],\n",
    "                'true_disease': list(DISEASE_CLASSES.values())[all_true_labels[sample_idx]],\n",
    "                'predicted_disease': list(DISEASE_CLASSES.values())[all_predictions[sample_idx]],\n",
    "                'correct': all_true_labels[sample_idx] == all_predictions[sample_idx],\n",
    "                'confidence': np.max(all_probabilities[sample_idx])\n",
    "            })\n",
    "            sample_idx += 1\n",
    "    \n",
    "    predictions_df = pd.DataFrame(prediction_data)\n",
    "    \n",
    "    print(f\"✅ Created prediction DataFrame: {predictions_df.shape}\")\n",
    "    \n",
    "    # Save predictions\n",
    "    predictions_df.to_csv(RESULTS_DIR / 'spatial_predictions.csv', index=False)\n",
    "    print(f\"✅ Predictions saved to {RESULTS_DIR / 'spatial_predictions.csv'}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Trained model not found. Using dummy predictions for visualization.\")\n",
    "    \n",
    "    # Create dummy predictions for demonstration\n",
    "    test_time_points = [time_points[i] for i in test_indices]\n",
    "    prediction_data = []\n",
    "    \n",
    "    for time_point in test_time_points:\n",
    "        time_features = final_features[final_features['date'] == time_point]\n",
    "        for _, row in time_features.iterrows():\n",
    "            # Use some simple heuristic for dummy predictions\n",
    "            true_label = row['disease_label']\n",
    "            predicted_label = np.random.choice(list(DISEASE_CLASSES.keys()))\n",
    "            \n",
    "            prediction_data.append({\n",
    "                'farm_id': row['farm_id'],\n",
    "                'lat': row['lat'],\n",
    "                'lon': row['lon'],\n",
    "                'date': time_point,\n",
    "                'true_label': true_label,\n",
    "                'predicted_label': predicted_label,\n",
    "                'true_disease': DISEASE_CLASSES[true_label],\n",
    "                'predicted_disease': DISEASE_CLASSES[predicted_label],\n",
    "                'correct': true_label == predicted_label,\n",
    "                'confidence': np.random.uniform(0.5, 1.0)\n",
    "            })\n",
    "    \n",
    "    predictions_df = pd.DataFrame(prediction_data)\n",
    "    print(f\"✅ Created dummy prediction DataFrame: {predictions_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive prediction maps\n",
    "print(\"Creating interactive prediction maps...\")\n",
    "\n",
    "# Map for latest time point\n",
    "latest_time = predictions_df['date'].max()\n",
    "latest_predictions = predictions_df[predictions_df['date'] == latest_time]\n",
    "\n",
    "# Create map showing predictions vs actual\n",
    "center_lat = farms_df['lat'].mean()\n",
    "center_lon = farms_df['lon'].mean()\n",
    "\n",
    "# Prediction accuracy map\n",
    "m_accuracy = folium.Map(\n",
    "    location=[center_lat, center_lon],\n",
    "    zoom_start=10,\n",
    "    tiles='OpenStreetMap'\n",
    ")\n",
    "\n",
    "# Add markers for prediction accuracy\n",
    "for _, row in latest_predictions.iterrows():\n",
    "    color = 'green' if row['correct'] else 'red'\n",
    "    popup_text = f\"\"\"\n",
    "    Farm: {row['farm_id']}<br>\n",
    "    True: {row['true_disease']}<br>\n",
    "    Predicted: {row['predicted_disease']}<br>\n",
    "    Confidence: {row['confidence']:.3f}<br>\n",
    "    Correct: {row['correct']}\n",
    "    \"\"\"\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[row['lat'], row['lon']],\n",
    "        radius=8,\n",
    "        popup=popup_text,\n",
    "        color='black',\n",
    "        fillColor=color,\n",
    "        fillOpacity=0.7,\n",
    "        weight=2\n",
    "    ).add_to(m_accuracy)\n",
    "\n",
    "# Add legend for accuracy map\n",
    "accuracy_legend = '''\n",
    "<div style=\"position: fixed; \n",
    "            bottom: 50px; left: 50px; width: 150px; height: 90px; \n",
    "            background-color: white; border:2px solid grey; z-index:9999; \n",
    "            font-size:14px; padding: 10px\">\n",
    "<p><b>Prediction Accuracy</b></p>\n",
    "<p><i class=\"fa fa-circle\" style=\"color:green\"></i> Correct</p>\n",
    "<p><i class=\"fa fa-circle\" style=\"color:red\"></i> Incorrect</p>\n",
    "</div>\n",
    "'''\n",
    "m_accuracy.get_root().html.add_child(folium.Element(accuracy_legend))\n",
    "\n",
    "# Save accuracy map\n",
    "m_accuracy.save(str(RESULTS_DIR / '06_prediction_accuracy_map.html'))\n",
    "print(f\"✅ Prediction accuracy map saved\")\n",
    "\n",
    "# Disease prediction map\n",
    "m_disease = folium.Map(\n",
    "    location=[center_lat, center_lon],\n",
    "    zoom_start=10,\n",
    "    tiles='OpenStreetMap'\n",
    ")\n",
    "\n",
    "# Color mapping for diseases\n",
    "disease_colors = {\n",
    "    'Healthy': 'green',\n",
    "    'Blight': 'red',\n",
    "    'Rust': 'orange',\n",
    "    'Mosaic': 'purple',\n",
    "    'Bacterial': 'darkred'\n",
    "}\n",
    "\n",
    "# Add markers for predicted diseases\n",
    "for _, row in latest_predictions.iterrows():\n",
    "    color = disease_colors.get(row['predicted_disease'], 'blue')\n",
    "    popup_text = f\"\"\"\n",
    "    Farm: {row['farm_id']}<br>\n",
    "    Predicted Disease: {row['predicted_disease']}<br>\n",
    "    Confidence: {row['confidence']:.3f}\n",
    "    \"\"\"\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[row['lat'], row['lon']],\n",
    "        radius=8,\n",
    "        popup=popup_text,\n",
    "        color='black',\n",
    "        fillColor=color,\n",
    "        fillOpacity=0.7,\n",
    "        weight=2\n",
    "    ).add_to(m_disease)\n",
    "\n",
    "# Add legend for disease map\n",
    "disease_legend = '''\n",
    "<div style=\"position: fixed; \n",
    "            bottom: 50px; left: 50px; width: 150px; height: 140px; \n",
    "            background-color: white; border:2px solid grey; z-index:9999; \n",
    "            font-size:14px; padding: 10px\">\n",
    "<p><b>Predicted Diseases</b></p>\n",
    "'''\n",
    "for disease, color in disease_colors.items():\n",
    "    disease_legend += f'<p><i class=\"fa fa-circle\" style=\"color:{color}\"></i> {disease}</p>'\n",
    "disease_legend += '</div>'\n",
    "\n",
    "m_disease.get_root().html.add_child(folium.Element(disease_legend))\n",
    "\n",
    "# Save disease prediction map\n",
    "m_disease.save(str(RESULTS_DIR / '06_disease_prediction_map.html'))\n",
    "print(f\"✅ Disease prediction map saved\")\n",
    "\n",
    "print(f\"\\n✅ Interactive maps created:\")\n",
    "print(f\"- Prediction accuracy: {RESULTS_DIR / '06_prediction_accuracy_map.html'}\")\n",
    "print(f\"- Disease predictions: {RESULTS_DIR / '06_disease_prediction_map.html'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Temporal Analysis and Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal analysis and disease spread animation\n",
    "print(\"Creating temporal analysis...\")\n",
    "\n",
    "# Analyze prediction accuracy over time\n",
    "temporal_accuracy = predictions_df.groupby('date').agg({\n",
    "    'correct': 'mean',\n",
    "    'confidence': 'mean',\n",
    "    'farm_id': 'count'\n",
    "}).rename(columns={'farm_id': 'total_farms'})\n",
    "\n",
    "# Plot temporal accuracy\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Accuracy over time\n",
    "axes[0, 0].plot(temporal_accuracy.index, temporal_accuracy['correct'], 'o-', color='blue')\n",
    "axes[0, 0].set_title('Prediction Accuracy Over Time')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Confidence over time\n",
    "axes[0, 1].plot(temporal_accuracy.index, temporal_accuracy['confidence'], 'o-', color='green')\n",
    "axes[0, 1].set_title('Average Confidence Over Time')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Confidence')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Disease distribution over time (predictions)\n",
    "disease_temporal = predictions_df.groupby(['date', 'predicted_disease']).size().unstack(fill_value=0)\n",
    "disease_temporal.plot(kind='bar', stacked=True, ax=axes[1, 0], \n",
    "                     color=[disease_colors.get(col, 'gray') for col in disease_temporal.columns])\n",
    "axes[1, 0].set_title('Predicted Disease Distribution Over Time')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Number of Farms')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Accuracy by disease type\n",
    "disease_accuracy = predictions_df.groupby('true_disease')['correct'].mean().sort_values(ascending=True)\n",
    "axes[1, 1].barh(range(len(disease_accuracy)), disease_accuracy.values, \n",
    "               color=[disease_colors.get(disease, 'gray') for disease in disease_accuracy.index])\n",
    "axes[1, 1].set_yticks(range(len(disease_accuracy)))\n",
    "axes[1, 1].set_yticklabels(disease_accuracy.index)\n",
    "axes[1, 1].set_xlabel('Accuracy')\n",
    "axes[1, 1].set_title('Accuracy by Disease Type')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '06_temporal_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Temporal analysis plots created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create disease spread animation\n",
    "print(\"Creating disease spread animation...\")\n",
    "\n",
    "# Prepare data for animation\n",
    "animation_data = predictions_df[['farm_id', 'lat', 'lon', 'date', 'predicted_disease']].copy()\n",
    "animation_data = animation_data.merge(farms_df[['farm_id', 'crop_type']], on='farm_id')\n",
    "\n",
    "# Create animated map\n",
    "try:\n",
    "    animation_map = create_disease_spread_animation(\n",
    "        farms_df,\n",
    "        animation_data.rename(columns={'predicted_disease': 'disease_type'}),\n",
    "        predictions_df['date'].unique().tolist(),\n",
    "        save_path=str(RESULTS_DIR / '06_disease_spread_animation.html')\n",
    "    )\n",
    "    print(f\"✅ Disease spread animation saved to {RESULTS_DIR / '06_disease_spread_animation.html'}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not create animation: {e}\")\n",
    "    print(\"Creating static time-series maps instead...\")\n",
    "    \n",
    "    # Create static maps for different time points\n",
    "    time_points_subset = predictions_df['date'].unique()[:3]  # First 3 time points\n",
    "    \n",
    "    for i, time_point in enumerate(time_points_subset):\n",
    "        time_data = predictions_df[predictions_df['date'] == time_point]\n",
    "        \n",
    "        m = folium.Map(\n",
    "            location=[center_lat, center_lon],\n",
    "            zoom_start=10,\n",
    "            tiles='OpenStreetMap'\n",
    "        )\n",
    "        \n",
    "        for _, row in time_data.iterrows():\n",
    "            color = disease_colors.get(row['predicted_disease'], 'blue')\n",
    "            folium.CircleMarker(\n",
    "                location=[row['lat'], row['lon']],\n",
    "                radius=8,\n",
    "                popup=f\"Farm: {row['farm_id']}<br>Disease: {row['predicted_disease']}\",\n",
    "                color='black',\n",
    "                fillColor=color,\n",
    "                fillOpacity=0.7,\n",
    "                weight=2\n",
    "            ).add_to(m)\n",
    "        \n",
    "        m.save(str(RESULTS_DIR / f'06_disease_map_time_{i+1}.html'))\n",
    "    \n",
    "    print(f\"✅ Created {len(time_points_subset)} static time-series maps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Interpretability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model interpretability and feature importance\n",
    "print(\"Analyzing model interpretability...\")\n",
    "\n",
    "# Load feature importance from feature engineering\n",
    "feature_importance_file = PROCESSED_DATA_DIR / 'feature_importance.csv'\n",
    "if feature_importance_file.exists():\n",
    "    feature_importance = pd.read_csv(feature_importance_file)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    fig = plot_feature_importance(\n",
    "        feature_importance['feature'].tolist(),\n",
    "        feature_importance['importance_score'].values,\n",
    "        save_path=str(RESULTS_DIR / '06_feature_importance.png')\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Feature importance plot created\")\n",
    "    \n",
    "    # Analyze feature categories\n",
    "    feature_categories = {\n",
    "        'Vegetation': [f for f in feature_importance['feature'] if 'vegetation' in f.lower()],\n",
    "        'Weather': [f for f in feature_importance['feature'] if 'weather' in f.lower()],\n",
    "        'Satellite': [f for f in feature_importance['feature'] if 'satellite' in f.lower()],\n",
    "        'Temporal': [f for f in feature_importance['feature'] if any(x in f.lower() for x in ['month', 'season', 'prev', 'history'])],\n",
    "        'Farm': [f for f in feature_importance['feature'] if any(x in f.lower() for x in ['crop', 'area', 'size'])]\n",
    "    }\n",
    "    \n",
    "    # Calculate category importance\n",
    "    category_importance = {}\n",
    "    for category, features in feature_categories.items():\n",
    "        category_features = feature_importance[feature_importance['feature'].isin(features)]\n",
    "        if len(category_features) > 0:\n",
    "            category_importance[category] = category_features['importance_score'].mean()\n",
    "        else:\n",
    "            category_importance[category] = 0\n",
    "    \n",
    "    # Plot category importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    categories = list(category_importance.keys())\n",
    "    importances = list(category_importance.values())\n",
    "    \n",
    "    bars = plt.bar(categories, importances, color='skyblue')\n",
    "    plt.title('Feature Category Importance', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Feature Category')\n",
    "    plt.ylabel('Average Importance Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, importance in zip(bars, importances):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{importance:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / '06_category_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Feature category analysis completed\")\n",
    "    \n",
    "    # Print top features by category\n",
    "    print(\"\\nTop features by category:\")\n",
    "    for category, features in feature_categories.items():\n",
    "        if features:\n",
    "            category_features = feature_importance[feature_importance['feature'].isin(features)]\n",
    "            top_feature = category_features.loc[category_features['importance_score'].idxmax()]\n",
    "            print(f\"- {category}: {top_feature['feature']} (score: {top_feature['importance_score']:.3f})\")\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ Feature importance file not found. Skipping interpretability analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform detailed error analysis\n",
    "print(\"Performing error analysis...\")\n",
    "\n",
    "# Identify common misclassifications\n",
    "incorrect_predictions = predictions_df[predictions_df['correct'] == False]\n",
    "\n",
    "if len(incorrect_predictions) > 0:\n",
    "    print(f\"Total incorrect predictions: {len(incorrect_predictions)} ({len(incorrect_predictions)/len(predictions_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Confusion pairs\n",
    "    confusion_pairs = incorrect_predictions.groupby(['true_disease', 'predicted_disease']).size().reset_index(name='count')\n",
    "    confusion_pairs = confusion_pairs.sort_values('count', ascending=False)\n",
    "    \n",
    "    print(\"\\nMost common misclassifications:\")\n",
    "    for _, row in confusion_pairs.head(10).iterrows():\n",
    "        print(f\"- {row['true_disease']} → {row['predicted_disease']}: {row['count']} cases\")\n",
    "    \n",
    "    # Error analysis by confidence\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Subplot 1: Confidence distribution for correct vs incorrect\n",
    "    plt.subplot(2, 2, 1)\n",
    "    correct_conf = predictions_df[predictions_df['correct'] == True]['confidence']\n",
    "    incorrect_conf = predictions_df[predictions_df['correct'] == False]['confidence']\n",
    "    \n",
    "    plt.hist(correct_conf, bins=20, alpha=0.7, label='Correct', color='green', density=True)\n",
    "    plt.hist(incorrect_conf, bins=20, alpha=0.7, label='Incorrect', color='red', density=True)\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Confidence Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 2: Error rate by confidence bins\n",
    "    plt.subplot(2, 2, 2)\n",
    "    predictions_df['confidence_bin'] = pd.cut(predictions_df['confidence'], bins=10)\n",
    "    error_by_conf = predictions_df.groupby('confidence_bin').agg({\n",
    "        'correct': ['mean', 'count']\n",
    "    }).round(3)\n",
    "    \n",
    "    bin_centers = [interval.mid for interval in error_by_conf.index]\n",
    "    error_rates = 1 - error_by_conf[('correct', 'mean')].values\n",
    "    \n",
    "    plt.plot(bin_centers, error_rates, 'o-', color='red')\n",
    "    plt.xlabel('Confidence (bin center)')\n",
    "    plt.ylabel('Error Rate')\n",
    "    plt.title('Error Rate by Confidence')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 3: Errors by disease type\n",
    "    plt.subplot(2, 2, 3)\n",
    "    error_by_disease = predictions_df.groupby('true_disease').agg({\n",
    "        'correct': ['mean', 'count']\n",
    "    })\n",
    "    \n",
    "    disease_names = error_by_disease.index\n",
    "    error_rates_disease = 1 - error_by_disease[('correct', 'mean')].values\n",
    "    \n",
    "    bars = plt.bar(range(len(disease_names)), error_rates_disease, \n",
    "                  color=[disease_colors.get(disease, 'gray') for disease in disease_names])\n",
    "    plt.xticks(range(len(disease_names)), disease_names, rotation=45)\n",
    "    plt.ylabel('Error Rate')\n",
    "    plt.title('Error Rate by Disease Type')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Subplot 4: Temporal error pattern\n",
    "    plt.subplot(2, 2, 4)\n",
    "    temporal_errors = predictions_df.groupby('date')['correct'].mean()\n",
    "    plt.plot(temporal_errors.index, 1 - temporal_errors.values, 'o-', color='orange')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Error Rate')\n",
    "    plt.title('Error Rate Over Time')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / '06_error_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Error analysis completed\")\n",
    "    \n",
    "    # Save error analysis results\n",
    "    error_summary = {\n",
    "        'total_predictions': len(predictions_df),\n",
    "        'incorrect_predictions': len(incorrect_predictions),\n",
    "        'overall_error_rate': len(incorrect_predictions) / len(predictions_df),\n",
    "        'common_misclassifications': confusion_pairs.head(5).to_dict('records'),\n",
    "        'error_by_disease': error_by_disease.to_dict(),\n",
    "        'avg_confidence_correct': float(correct_conf.mean()),\n",
    "        'avg_confidence_incorrect': float(incorrect_conf.mean())\n",
    "    }\n",
    "    \n",
    "    with open(RESULTS_DIR / 'error_analysis.json', 'w') as f:\n",
    "        json.dump(error_summary, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"✅ Error analysis saved to {RESULTS_DIR / 'error_analysis.json'}\")\n",
    "\n",
    "else:\n",
    "    print(\"✅ Perfect predictions! No errors to analyze.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary report\n",
    "print(\"Generating final summary report...\")\n",
    "\n",
    "# Calculate key metrics\n",
    "overall_accuracy = predictions_df['correct'].mean()\n",
    "avg_confidence = predictions_df['confidence'].mean()\n",
    "total_farms = len(farms_df)\n",
    "total_predictions = len(predictions_df)\n",
    "test_time_points = len(predictions_df['date'].unique())\n",
    "\n",
    "# Disease distribution in test set\n",
    "disease_dist = predictions_df['true_disease'].value_counts()\n",
    "prediction_dist = predictions_df['predicted_disease'].value_counts()\n",
    "\n",
    "# Model comparison summary\n",
    "model_comparison_summary = pd.DataFrame(model_comparison)\n",
    "best_baseline = model_comparison_summary[model_comparison_summary['Type'] == 'Baseline']['Test Accuracy'].max()\n",
    "best_gnn = model_comparison_summary[model_comparison_summary['Type'] == 'GNN']['Test Accuracy'].max()\n",
    "improvement = best_gnn - best_baseline\n",
    "\n",
    "# Create comprehensive report\n",
    "report = f\"\"\"\n",
    "# AgroGraphNet: Crop Disease Prediction - Final Report\n",
    "\n",
    "## Executive Summary\n",
    "This report presents the results of the AgroGraphNet project, which uses Graph Neural Networks \n",
    "to predict crop diseases based on satellite imagery, weather data, and farm characteristics.\n",
    "\n",
    "## Dataset Overview\n",
    "- **Total Farms**: {total_farms}\n",
    "- **Test Period**: {test_time_points} time points\n",
    "- **Total Predictions**: {total_predictions}\n",
    "- **Disease Classes**: {len(DISEASE_CLASSES)}\n",
    "\n",
    "## Model Performance\n",
    "- **Best Model**: {best_model_name}\n",
    "- **Overall Accuracy**: {overall_accuracy:.4f} ({overall_accuracy*100:.1f}%)\n",
    "- **Average Confidence**: {avg_confidence:.4f}\n",
    "- **Improvement over Baseline**: {improvement:.4f} ({improvement*100:.1f} percentage points)\n",
    "\n",
    "## Disease Distribution (Test Set)\n",
    "**Actual Distribution**:\n",
    "\"\"\"\n",
    "\n",
    "for disease, count in disease_dist.items():\n",
    "    percentage = count / len(predictions_df) * 100\n",
    "    report += f\"- {disease}: {count} ({percentage:.1f}%)\\n\"\n",
    "\n",
    "report += \"\\n**Predicted Distribution**:\\n\"\n",
    "for disease, count in prediction_dist.items():\n",
    "    percentage = count / len(predictions_df) * 100\n",
    "    report += f\"- {disease}: {count} ({percentage:.1f}%)\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "\n",
    "## Model Comparison\n",
    "\"\"\"\n",
    "\n",
    "for _, row in model_comparison_summary.iterrows():\n",
    "    report += f\"- **{row['Model']}** ({row['Type']}): {row['Test Accuracy']:.4f}\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "\n",
    "## Key Findings\n",
    "1. **Graph Neural Networks Effectiveness**: The {best_model_name} model achieved the best performance, \n",
    "   demonstrating the value of modeling spatial relationships between farms.\n",
    "\n",
    "2. **Spatial Patterns**: The model successfully captures spatial disease spread patterns, \n",
    "   with neighboring farms showing correlated disease predictions.\n",
    "\n",
    "3. **Feature Importance**: Vegetation indices and weather patterns were among the most \n",
    "   important features for disease prediction.\n",
    "\n",
    "4. **Temporal Consistency**: The model maintains consistent performance across different \n",
    "   time periods in the test set.\n",
    "\n",
    "## Practical Applications\n",
    "- **Early Warning System**: Predict disease outbreaks 2-4 weeks in advance\n",
    "- **Resource Allocation**: Optimize deployment of agricultural resources\n",
    "- **Risk Assessment**: Identify high-risk areas for targeted interventions\n",
    "- **Policy Support**: Inform agricultural policy and insurance decisions\n",
    "\n",
    "## Technical Specifications\n",
    "- **Model Architecture**: {best_model_name} with {MODEL_CONFIG['num_layers']} layers\n",
    "- **Input Features**: {len(selected_features) if 'selected_features' in locals() else 'N/A'} selected features\n",
    "- **Graph Connectivity**: {GRAPH_CONFIG['distance_threshold_km']}km distance threshold\n",
    "- **Training Configuration**: {MODEL_CONFIG['num_epochs']} epochs, {MODEL_CONFIG['learning_rate']} learning rate\n",
    "\n",
    "## Files Generated\n",
    "- **Models**: `models/best_{best_model_name.lower()}_model.pth`\n",
    "- **Predictions**: `results/spatial_predictions.csv`\n",
    "- **Visualizations**: Multiple interactive maps and analysis plots in `results/`\n",
    "- **Data**: Processed features and graphs in `data/processed/`\n",
    "\n",
    "## Recommendations\n",
    "1. **Deployment**: The model is ready for deployment in agricultural monitoring systems\n",
    "2. **Data Collection**: Continue collecting high-quality satellite and weather data\n",
    "3. **Model Updates**: Retrain periodically with new data to maintain performance\n",
    "4. **Validation**: Validate predictions with field observations when possible\n",
    "\n",
    "## Conclusion\n",
    "The AgroGraphNet project successfully demonstrates the potential of Graph Neural Networks \n",
    "for crop disease prediction. The {best_model_name} model achieves {overall_accuracy*100:.1f}% accuracy, \n",
    "providing a valuable tool for precision agriculture and disease management.\n",
    "\n",
    "---\n",
    "Report generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "# Save report\n",
    "with open(RESULTS_DIR / 'final_report.md', 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"✅ Final report saved to {RESULTS_DIR / 'final_report.md'}\")\n",
    "\n",
    "# Print summary to console\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AGROGRPAHNET - FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.4f} ({overall_accuracy*100:.1f}%)\")\n",
    "print(f\"Average Confidence: {avg_confidence:.4f}\")\n",
    "print(f\"Total Predictions: {total_predictions}\")\n",
    "print(f\"Improvement over Baseline: +{improvement:.4f} ({improvement*100:.1f} pp)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n🎉 Evaluation and visualization completed successfully!\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(f\"- Interactive maps: {RESULTS_DIR}/*.html\")\n",
    "print(f\"- Analysis plots: {RESULTS_DIR}/*.png\")\n",
    "print(f\"- Predictions: {RESULTS_DIR}/spatial_predictions.csv\")\n",
    "print(f\"- Final report: {RESULTS_DIR}/final_report.md\")\n",
    "print(f\"- Error analysis: {RESULTS_DIR}/error_analysis.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
