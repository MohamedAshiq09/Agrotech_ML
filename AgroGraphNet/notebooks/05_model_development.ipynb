{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgroGraphNet: Model Development\n",
    "\n",
    "This notebook develops and trains Graph Neural Network models for crop disease prediction.\n",
    "\n",
    "## Objectives:\n",
    "1. Create PyTorch Geometric graphs from engineered features\n",
    "2. Implement and train different GNN architectures (GCN, GraphSAGE, GAT)\n",
    "3. Train baseline models for comparison\n",
    "4. Hyperparameter tuning and model selection\n",
    "5. Model evaluation and performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from config import *\n",
    "from graph_utils import *\n",
    "from model_utils import *\n",
    "from visualization import *\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph data from previous notebook\n",
    "print(\"Loading graph data...\")\n",
    "\n",
    "graph_file = GRAPHS_DIR / 'farm_graphs.pkl'\n",
    "if graph_file.exists():\n",
    "    with open(graph_file, 'rb') as f:\n",
    "        graph_data = pickle.load(f)\n",
    "    \n",
    "    pytorch_graphs = graph_data['pytorch_graphs']\n",
    "    farms_df = graph_data['farms_df']\n",
    "    time_points = graph_data['time_points']\n",
    "    \n",
    "    print(f\"‚úÖ Loaded graph data: {len(pytorch_graphs)} graphs\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Graph data not found. Creating basic graphs from available data...\")\n",
    "    \n",
    "    # Load basic data and create simple graphs\n",
    "    farm_files = list(FARM_LOCATIONS_DIR.glob('*.csv'))\n",
    "    if not farm_files:\n",
    "        raise FileNotFoundError(\"No farm data found. Please run previous notebooks first.\")\n",
    "    \n",
    "    farms_df = pd.read_csv(farm_files[0])\n",
    "    \n",
    "    # Create basic graphs\n",
    "    pytorch_graphs = create_basic_graphs(farms_df)\n",
    "    time_points = [f\"2023-{i+1:02d}-01\" for i in range(len(pytorch_graphs))]\n",
    "    \n",
    "    print(f\"‚úÖ Created basic graphs: {len(pytorch_graphs)} graphs\")\n",
    "\n",
    "# Display graph information\n",
    "sample_graph = pytorch_graphs[0]\n",
    "print(f\"\\nGraph information:\")\n",
    "print(f\"- Number of graphs: {len(pytorch_graphs)}\")\n",
    "print(f\"- Nodes per graph: {sample_graph.x.shape[0]}\")\n",
    "print(f\"- Node features: {sample_graph.x.shape[1]}\")\n",
    "print(f\"- Edges per graph: {sample_graph.edge_index.shape[1]}\")\n",
    "print(f\"- Classes: {len(torch.unique(sample_graph.y))}\")\n",
    "print(f\"- Class distribution: {torch.bincount(sample_graph.y).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_graphs(farms_df, num_time_points=12):\n",
    "    \"\"\"\n",
    "    Create basic graphs when processed data is not available\n",
    "    \"\"\"\n",
    "    print(\"Creating basic graphs...\")\n",
    "    \n",
    "    graphs = []\n",
    "    \n",
    "    # Create distance matrix\n",
    "    distance_matrix = create_distance_matrix(farms_df)\n",
    "    \n",
    "    # Create adjacency matrix\n",
    "    adjacency_matrix = create_adjacency_matrix(distance_matrix, threshold_km=5.0)\n",
    "    \n",
    "    for t in range(num_time_points):\n",
    "        # Create basic node features\n",
    "        node_features = []\n",
    "        labels = []\n",
    "        \n",
    "        for _, farm in farms_df.iterrows():\n",
    "            # Basic features: lat, lon, area, crop type (one-hot)\n",
    "            features = [farm['lat'], farm['lon'], farm['area_hectares']]\n",
    "            \n",
    "            # Add crop type one-hot encoding\n",
    "            crop_types = farms_df['crop_type'].unique()\n",
    "            for crop in crop_types:\n",
    "                features.append(1.0 if farm['crop_type'] == crop else 0.0)\n",
    "            \n",
    "            # Add temporal features\n",
    "            features.extend([t / num_time_points, np.sin(2 * np.pi * t / 12), np.cos(2 * np.pi * t / 12)])\n",
    "            \n",
    "            # Add some random environmental features\n",
    "            features.extend(np.random.normal(0, 1, 5))\n",
    "            \n",
    "            node_features.append(features)\n",
    "            \n",
    "            # Random disease labels with higher probability of healthy\n",
    "            label = np.random.choice([0, 1, 2, 3, 4], p=[0.7, 0.1, 0.1, 0.05, 0.05])\n",
    "            labels.append(label)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "        y = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        # Create edge index from adjacency matrix\n",
    "        edge_indices = np.where(adjacency_matrix == 1)\n",
    "        edge_index = torch.tensor([edge_indices[0], edge_indices[1]], dtype=torch.long)\n",
    "        \n",
    "        # Create edge attributes (distances)\n",
    "        edge_attr = []\n",
    "        for i in range(edge_index.shape[1]):\n",
    "            src, dst = edge_index[0, i].item(), edge_index[1, i].item()\n",
    "            dist = distance_matrix[src, dst]\n",
    "            edge_attr.append([dist, 1.0])  # distance and similarity\n",
    "        \n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "        \n",
    "        # Create PyTorch Geometric data object\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "        graphs.append(data)\n",
    "    \n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/validation/test sets\n",
    "print(\"Splitting data into train/validation/test sets...\")\n",
    "\n",
    "# Temporal split: use first 60% for training, next 20% for validation, last 20% for testing\n",
    "n_time_points = len(pytorch_graphs)\n",
    "train_end = int(0.6 * n_time_points)\n",
    "val_end = int(0.8 * n_time_points)\n",
    "\n",
    "train_graphs = pytorch_graphs[:train_end]\n",
    "val_graphs = pytorch_graphs[train_end:val_end]\n",
    "test_graphs = pytorch_graphs[val_end:]\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"- Training: {len(train_graphs)} time points\")\n",
    "print(f\"- Validation: {len(val_graphs)} time points\")\n",
    "print(f\"- Testing: {len(test_graphs)} time points\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = MODEL_CONFIG['batch_size']\n",
    "\n",
    "train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaders created with batch size: {batch_size}\")\n",
    "\n",
    "# Check class distribution\n",
    "train_labels = torch.cat([data.y for data in train_graphs])\n",
    "val_labels = torch.cat([data.y for data in val_graphs])\n",
    "test_labels = torch.cat([data.y for data in test_graphs])\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"Training: {torch.bincount(train_labels).tolist()}\")\n",
    "print(f\"Validation: {torch.bincount(val_labels).tolist()}\")\n",
    "print(f\"Testing: {torch.bincount(test_labels).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline models for comparison\n",
    "print(\"Training baseline models...\")\n",
    "\n",
    "# Prepare data for baseline models (flatten temporal dimension)\n",
    "X_train = torch.cat([data.x for data in train_graphs]).numpy()\n",
    "y_train = torch.cat([data.y for data in train_graphs]).numpy()\n",
    "\n",
    "X_val = torch.cat([data.x for data in val_graphs]).numpy()\n",
    "y_val = torch.cat([data.y for data in val_graphs]).numpy()\n",
    "\n",
    "X_test = torch.cat([data.x for data in test_graphs]).numpy()\n",
    "y_test = torch.cat([data.y for data in test_graphs]).numpy()\n",
    "\n",
    "print(f\"Baseline data shapes:\")\n",
    "print(f\"- X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"- X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"- X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# Train baseline models\n",
    "baseline_results = create_baseline_models(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"\\n‚úÖ Baseline models trained\")\n",
    "print(\"\\nBaseline Results:\")\n",
    "for model_name, results in baseline_results.items():\n",
    "    print(f\"{model_name}: {results['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GNN Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train different GNN architectures\n",
    "print(\"Training GNN models...\")\n",
    "\n",
    "# Model parameters\n",
    "input_dim = pytorch_graphs[0].x.shape[1]\n",
    "hidden_dim = MODEL_CONFIG['hidden_dim']\n",
    "output_dim = len(DISEASE_CLASSES)\n",
    "num_layers = MODEL_CONFIG['num_layers']\n",
    "dropout = MODEL_CONFIG['dropout']\n",
    "learning_rate = MODEL_CONFIG['learning_rate']\n",
    "num_epochs = MODEL_CONFIG['num_epochs']\n",
    "early_stopping_patience = MODEL_CONFIG['early_stopping_patience']\n",
    "\n",
    "print(f\"Model configuration:\")\n",
    "print(f\"- Input dim: {input_dim}\")\n",
    "print(f\"- Hidden dim: {hidden_dim}\")\n",
    "print(f\"- Output dim: {output_dim}\")\n",
    "print(f\"- Num layers: {num_layers}\")\n",
    "print(f\"- Dropout: {dropout}\")\n",
    "print(f\"- Learning rate: {learning_rate}\")\n",
    "print(f\"- Epochs: {num_epochs}\")\n",
    "\n",
    "# Dictionary to store results\n",
    "gnn_results = {}\n",
    "\n",
    "# Train GCN model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training GCN Model\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "gcn_model = GCNModel(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "gcn_results = train_and_evaluate(\n",
    "    model=gcn_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    early_stopping_patience=early_stopping_patience,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "gnn_results['GCN'] = gcn_results\n",
    "\n",
    "# Train GraphSAGE model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training GraphSAGE Model\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "sage_model = GraphSAGEModel(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "sage_results = train_and_evaluate(\n",
    "    model=sage_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    early_stopping_patience=early_stopping_patience,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "gnn_results['GraphSAGE'] = sage_results\n",
    "\n",
    "# Train GAT model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training GAT Model\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "gat_model = GATModel(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "gat_results = train_and_evaluate(\n",
    "    model=gat_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    early_stopping_patience=early_stopping_patience,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "gnn_results['GAT'] = gat_results\n",
    "\n",
    "print(\"\\n‚úÖ All GNN models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all model results\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine baseline and GNN results\n",
    "all_results = {}\n",
    "\n",
    "# Add baseline results\n",
    "for model_name, results in baseline_results.items():\n",
    "    all_results[model_name] = {\n",
    "        'test_accuracy': results['test_accuracy'],\n",
    "        'model_type': 'Baseline'\n",
    "    }\n",
    "\n",
    "# Add GNN results\n",
    "for model_name, results in gnn_results.items():\n",
    "    all_results[model_name] = {\n",
    "        'test_accuracy': results['test_accuracy'],\n",
    "        'model_type': 'GNN'\n",
    "    }\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame([\n",
    "    {'Model': name, 'Test Accuracy': results['test_accuracy'], 'Type': results['model_type']}\n",
    "    for name, results in all_results.items()\n",
    "]).sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_accuracy = comparison_df.iloc[0]['Test Accuracy']\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name} (Accuracy: {best_accuracy:.4f})\")\n",
    "\n",
    "# Get best GNN model\n",
    "best_gnn = max(gnn_results.items(), key=lambda x: x[1]['test_accuracy'])\n",
    "best_gnn_name, best_gnn_results = best_gnn\n",
    "\n",
    "print(f\"ü•á Best GNN Model: {best_gnn_name} (Accuracy: {best_gnn_results['test_accuracy']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig = plot_model_comparison(\n",
    "    baseline_results, \n",
    "    best_gnn_results,\n",
    "    save_path=str(RESULTS_DIR / '05_model_comparison.png')\n",
    ")\n",
    "\n",
    "# Plot training history for best GNN model\n",
    "if 'train_losses' in best_gnn_results and 'val_accuracies' in best_gnn_results:\n",
    "    fig = plot_training_history(\n",
    "        best_gnn_results['train_losses'],\n",
    "        best_gnn_results['val_accuracies'],\n",
    "        save_path=str(RESULTS_DIR / f'05_{best_gnn_name}_training_history.png')\n",
    "    )\n",
    "\n",
    "# Plot confusion matrix for best GNN model\n",
    "if 'test_labels' in best_gnn_results and 'test_predictions' in best_gnn_results:\n",
    "    class_names = list(DISEASE_CLASSES.values())\n",
    "    fig = plot_confusion_matrix(\n",
    "        best_gnn_results['test_labels'],\n",
    "        best_gnn_results['test_predictions'],\n",
    "        class_names=class_names,\n",
    "        save_path=str(RESULTS_DIR / f'05_{best_gnn_name}_confusion_matrix.png')\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Visualizations created and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models and results\n",
    "print(\"Saving models and results...\")\n",
    "\n",
    "# Save best GNN model\n",
    "best_model_path = MODELS_DIR / f'best_{best_gnn_name.lower()}_model.pth'\n",
    "torch.save(best_gnn_results['model_state_dict'], best_model_path)\n",
    "print(f\"‚úÖ Best model saved to {best_model_path}\")\n",
    "\n",
    "# Save all results\n",
    "results_data = {\n",
    "    'baseline_results': baseline_results,\n",
    "    'gnn_results': gnn_results,\n",
    "    'best_model_name': best_gnn_name,\n",
    "    'best_model_accuracy': best_gnn_results['test_accuracy'],\n",
    "    'model_comparison': comparison_df.to_dict('records'),\n",
    "    'model_config': MODEL_CONFIG,\n",
    "    'graph_config': GRAPH_CONFIG\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results_data, f)\n",
    "\n",
    "print(f\"‚úÖ Results saved to {RESULTS_DIR / 'model_results.pkl'}\")\n",
    "\n",
    "# Save model summary as JSON\n",
    "summary_data = {\n",
    "    'best_model': best_gnn_name,\n",
    "    'best_accuracy': float(best_gnn_results['test_accuracy']),\n",
    "    'model_comparison': {\n",
    "        name: float(results['test_accuracy']) \n",
    "        for name, results in all_results.items()\n",
    "    },\n",
    "    'training_config': MODEL_CONFIG,\n",
    "    'num_graphs': len(pytorch_graphs),\n",
    "    'num_nodes': pytorch_graphs[0].x.shape[0],\n",
    "    'node_features': pytorch_graphs[0].x.shape[1]\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'model_summary.json', 'w') as f:\n",
    "    json.dump(summary_data, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Model summary saved to {RESULTS_DIR / 'model_summary.json'}\")\n",
    "\n",
    "print(\"\\nüéâ Model development completed successfully!\")\n",
    "print(\"\\nFinal Results Summary:\")\n",
    "print(f\"- Best Model: {best_gnn_name}\")\n",
    "print(f\"- Best Accuracy: {best_gnn_results['test_accuracy']:.4f}\")\n",
    "print(f\"- Improvement over best baseline: {best_gnn_results['test_accuracy'] - max(baseline_results.values(), key=lambda x: x['test_accuracy'])['test_accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run notebook 06_evaluation_visualization.ipynb\")\n",
    "print(\"2. Create detailed visualizations and analysis\")\n",
    "print(\"3. Generate prediction maps and reports\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
    'distance_threshold_km': 5.0,
    'min_neighbors': 2,
    'max_neighbors': 10
}

# Create directories
def create_directories():
    """Create necessary directories if they don't exist"""
    dirs = ['data/processed', 'models', 'results']
    for dir_path in dirs:
        Path(dir_path).mkdir(parents=True, exist_ok=True)

create_directories()

PROCESSED_DATA_DIR = Path('data/processed')
MODELS_DIR = Path('models')
RESULTS_DIR = Path('results')

# Set random seed for reproducibility
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

def create_sample_data():
    """Create sample agricultural data if not available"""
    print("Creating sample agricultural data...")
    
    # Generate sample farms
    n_farms = 100
    n_time_points = 20
    
    # Create farm locations (latitude, longitude)
    np.random.seed(RANDOM_SEED)
    farms_data = []
    for i in range(n_farms):
        farms_data.append({
            'farm_id': f'FARM_{i:03d}',
            'latitude': 40.0 + np.random.normal(0, 0.1),  # Around 40¬∞N
            'longitude': -74.0 + np.random.normal(0, 0.1),  # Around 74¬∞W
            'farm_size': np.random.uniform(10, 500),  # hectares
            'crop_type': np.random.choice(['corn', 'wheat', 'soybean', 'rice'])
        })
    
    farms_df = pd.DataFrame(farms_data)
    
    # Generate time points
    start_date = datetime(2023, 1, 1)
    time_points = [(start_date + timedelta(weeks=i*2)).strftime('%Y-%m-%d') 
                   for i in range(n_time_points)]
    
    # Generate node features and labels for each time point
    n_features = 15
    feature_names = [
        'temperature', 'humidity', 'rainfall', 'soil_ph', 'soil_moisture',
        'nitrogen', 'phosphorus', 'potassium', 'organic_matter', 'elevation',
        'slope', 'aspect', 'irrigation', 'fertilizer_applied', 'pesticide_applied'
    ]
    
    node_features_by_time = {}
    labels_by_time = {}
    edge_features_by_time = {}
    
    for time_point in time_points:
        # Generate node features
        features = np.random.randn(n_farms, n_features)
        # Add some structure to make it more realistic
        features[:, 0] += 20  # temperature around 20¬∞C
        features[:, 1] = np.abs(features[:, 1]) * 50 + 30  # humidity 30-130%
        features[:, 2] = np.abs(features[:, 2]) * 20  # rainfall 0-20mm
        features[:, 3] = features[:, 3] * 0.5 + 6.5  # soil pH around 6.5
        
        node_features_by_time[time_point] = features
        
        # Generate labels with some correlation to features
        disease_prob = 1 / (1 + np.exp(-(features[:, 1] - 80) / 10))  # High humidity -> disease
        labels = np.random.choice(len(DISEASE_CLASSES), size=n_farms, 
                                 p=[0.4, 0.2, 0.2, 0.1, 0.1])
        labels_by_time[time_point] = labels
        
        # Generate edge features (simplified)
        edge_features_by_time[time_point] = np.random.randn(n_farms, n_farms, 3)
    
    # Calculate distance matrix
    coords = farms_df[['latitude', 'longitude']].values
    distance_matrix = squareform(pdist(coords, metric='euclidean')) * 111  # Convert to km
    
    # Create feature summary
    summary_stats = {
        'total_farms': n_farms,
        'total_time_points': n_time_points,
        'feature_dimension': n_features,
        'disease_classes': len(DISEASE_CLASSES)
    }
    
    # Save data
    feature_data = {
        'node_features_by_time': node_features_by_time,
        'labels_by_time': labels_by_time,
        'edge_features_by_time': edge_features_by_time,
        'selected_features': feature_names,
        'time_points': time_points,
        'farms_df': farms_df,
        'distance_matrix': distance_matrix
    }
    
    with open(PROCESSED_DATA_DIR / 'engineered_features.pkl', 'wb') as f:
        pickle.dump(feature_data, f)
    
    with open(PROCESSED_DATA_DIR / 'feature_summary.json', 'w') as f:
        json.dump(summary_stats, f, indent=2)
    
    print("‚úÖ Sample data created successfully!")
    return feature_data, summary_stats

def create_adjacency_matrix(distance_matrix, threshold_km=5.0, min_neighbors=2, max_neighbors=10):
    """Create adjacency matrix based on distance threshold"""
    n_nodes = distance_matrix.shape[0]
    adjacency = np.zeros((n_nodes, n_nodes))
    
    for i in range(n_nodes):
        # Get distances to all other nodes
        distances = distance_matrix[i]
        
        # Find neighbors within threshold
        neighbor_indices = np.where((distances <= threshold_km) & (distances > 0))[0]
        
        # Ensure minimum neighbors
        if len(neighbor_indices) < min_neighbors:
            # Add closest neighbors
            sorted_indices = np.argsort(distances)
            neighbor_indices = sorted_indices[1:min_neighbors+1]  # Exclude self
        
        # Limit maximum neighbors
        if len(neighbor_indices) > max_neighbors:
            # Keep only closest neighbors
            distances_subset = distances[neighbor_indices]
            closest_indices = np.argsort(distances_subset)[:max_neighbors]
            neighbor_indices = neighbor_indices[closest_indices]
        
        # Set adjacency
        adjacency[i, neighbor_indices] = 1
    
    # Make symmetric
    adjacency = np.maximum(adjacency, adjacency.T)
    
    return adjacency

def create_networkx_graph(adjacency_matrix, node_features, edge_features, farms_df):
    """Create NetworkX graph from adjacency matrix and features"""
    G = nx.Graph()
    
    # Add nodes with features
    for i in range(len(farms_df)):
        G.add_node(i, features=node_features[i], **farms_df.iloc[i].to_dict())
    
    # Add edges
    rows, cols = np.where(adjacency_matrix > 0)
    for i, j in zip(rows, cols):
        if i < j:  # Avoid duplicate edges
            edge_attr = edge_features[i, j] if edge_features.ndim == 3 else [1.0]
            G.add_edge(i, j, weight=edge_attr[0] if len(edge_attr) > 0 else 1.0)
    
    return G

def networkx_to_pytorch_geometric(G, labels):
    """Convert NetworkX graph to PyTorch Geometric Data object"""
    # Get node features
    node_features = np.array([G.nodes[i]['features'] for i in G.nodes()])
    x = torch.FloatTensor(node_features)
    
    # Get edge indices
    edge_index = torch.LongTensor(list(G.edges())).t().contiguous()
    
    # Get edge attributes (weights)
    edge_attr = torch.FloatTensor([G[u][v]['weight'] for u, v in G.edges()])
    edge_attr = edge_attr.unsqueeze(1)  # Add feature dimension
    
    # Get labels
    y = torch.LongTensor(labels)
    
    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)

# =============================================================================
# MODEL DEFINITIONS
# =============================================================================

class GCNModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3, dropout=0.3):
        super(GCNModel, self).__init__()
        self.convs = nn.ModuleList()
        self.bns = nn.ModuleList()
        self.dropout = dropout
        
        # First layer
        self.convs.append(GCNConv(input_dim, hidden_dim))
        self.bns.append(nn.BatchNorm1d(hidden_dim))
        
        # Hidden layers
        for _ in range(num_layers - 2):
            self.convs.append(GCNConv(hidden_dim, hidden_dim))
            self.bns.append(nn.BatchNorm1d(hidden_dim))
        
        # Output layer
        self.convs.append(GCNConv(hidden_dim, output_dim))
        
    def forward(self, x, edge_index, batch=None):
        # Apply graph convolutions
        for i, conv in enumerate(self.convs[:-1]):
            x = conv(x, edge_index)
            x = self.bns[i](x)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
        
        # Final layer
        x = self.convs[-1](x, edge_index)
        
        # Global pooling for graph-level prediction
        if batch is not None:
            x = global_mean_pool(x, batch)
        
        return F.log_softmax(x, dim=1)

class GraphSAGEModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3, dropout=0.3):
        super(GraphSAGEModel, self).__init__()
        self.convs = nn.ModuleList()
        self.bns = nn.ModuleList()
        self.dropout = dropout
        
        # First layer
        self.convs.append(SAGEConv(input_dim, hidden_dim))
        self.bns.append(nn.BatchNorm1d(hidden_dim))
        
        # Hidden layers
        for _ in range(num_layers - 2):
            self.convs.append(SAGEConv(hidden_dim, hidden_dim))
            self.bns.append(nn.BatchNorm1d(hidden_dim))
        
        # Output layer
        self.convs.append(SAGEConv(hidden_dim, output_dim))
        
    def forward(self, x, edge_index, batch=None):
        for i, conv in enumerate(self.convs[:-1]):
            x = conv(x, edge_index)
            x = self.bns[i](x)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
        
        x = self.convs[-1](x, edge_index)
        
        if batch is not None:
            x = global_mean_pool(x, batch)
        
        return F.log_softmax(x, dim=1)

class GATModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3, dropout=0.3, heads=4):
        super(GATModel, self).__init__()
        self.convs = nn.ModuleList()
        self.bns = nn.ModuleList()
        self.dropout = dropout
        self.heads = heads
        
        # First layer
        self.convs.append(GATConv(input_dim, hidden_dim // heads, heads=heads, dropout=dropout))
        self.bns.append(nn.BatchNorm1d(hidden_dim))
        
        # Hidden layers
        for _ in range(num_layers - 2):
            self.convs.append(GATConv(hidden_dim, hidden_dim // heads, heads=heads, dropout=dropout))
            self.bns.append(nn.BatchNorm1d(hidden_dim))
        
        # Output layer
        self.convs.append(GATConv(hidden_dim, output_dim, heads=1, dropout=dropout))
        
    def forward(self, x, edge_index, batch=None):
        for i, conv in enumerate(self.convs[:-1]):
            x = conv(x, edge_index)
            x = self.bns[i](x)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
        
        x = self.convs[-1](x, edge_index)
        
        if batch is not None:
            x = global_mean_pool(x, batch)
        
        return F.log_softmax(x, dim=1)

# =============================================================================
# TRAINING AND EVALUATION FUNCTIONS
# =============================================================================

def train_and_evaluate(model, train_loader, val_loader, test_loader, num_epochs=100, 
                      learning_rate=0.001, early_stopping_patience=10, device='cpu'):
    """Train and evaluate a GNN model"""
    model = model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)
    criterion = nn.NLLLoss()
    
    train_losses = []
    val_accuracies = []
    best_val_acc = 0
    patience_counter = 0
    best_model_state = None
    
    print(f"Training {model.__class__.__name__}...")
    
    for epoch in range(num_epochs):
        # Training
        model.train()
        total_loss = 0
        for batch in train_loader:
            batch = batch.to(device)
            optimizer.zero_grad()
            out = model(batch.x, batch.edge_index, batch.batch)
            loss = criterion(out, batch.y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        avg_loss = total_loss / len(train_loader)
        train_losses.append(avg_loss)
        
        # Validation
        model.eval()
        val_correct = 0
        val_total = 0
        with torch.no_grad():
            for batch in val_loader:
                batch = batch.to(device)
                out = model(batch.x, batch.edge_index, batch.batch)
                pred = out.argmax(dim=1)
                val_correct += (pred == batch.y).sum().item()
                val_total += batch.y.size(0)
        
        val_acc = val_correct / val_total
        val_accuracies.append(val_acc)
        
        # Early stopping
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            patience_counter = 0
            best_model_state = model.state_dict().copy()
        else:
            patience_counter += 1
        
        if epoch % 10 == 0:
            print(f"Epoch {epoch:3d}: Loss = {avg_loss:.4f}, Val Acc = {val_acc:.4f}")
        
        if patience_counter >= early_stopping_patience:
            print(f"Early stopping at epoch {epoch}")
            break
    
    # Load best model
    model.load_state_dict(best_model_state)
    
    # Test evaluation
    model.eval()
    test_predictions = []
    test_labels = []
    test_correct = 0
    test_total = 0
    
    with torch.no_grad():
        for batch in test_loader:
            batch = batch.to(device)
            out = model(batch.x, batch.edge_index, batch.batch)
            pred = out.argmax(dim=1)
            test_predictions.extend(pred.cpu().numpy())
            test_labels.extend(batch.y.cpu().numpy())
            test_correct += (pred == batch.y).sum().item()
            test_total += batch.y.size(0)
    
    test_acc = test_correct / test_total
    
    # Classification report
    test_predictions = np.array(test_predictions)
    test_labels = np.array(test_labels)
    
    class_names = [DISEASE_CLASSES[i] for i in range(len(DISEASE_CLASSES))]
    report = classification_report(test_labels, test_predictions, 
                                 target_names=class_names, output_dict=True)
    
    print(f"Final Test Accuracy: {test_acc:.4f}")
    
    return {
        'model_state_dict': best_model_state,
        'train_losses': train_losses,
        'val_accuracies': val_accuracies,
        'test_accuracy': test_acc,
        'test_predictions': test_predictions,
        'test_labels': test_labels,
        'classification_report': report,
        'best_val_accuracy': best_val_acc
    }

def create_baseline_models(X_train, y_train, X_test, y_test):
    """Create and train baseline models"""
    print("Training baseline models...")
    
    # Standardize features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    models = {
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED),
        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_SEED),
        'SVM': SVC(kernel='rbf', random_state=RANDOM_SEED),
        'Logistic Regression': LogisticRegression(random_state=RANDOM_SEED, max_iter=1000)
    }
    
    results = {}
    
    for name, model in models.items():
        print(f"Training {name}...")
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)
        
        results[name] = {
            'model': model,
            'test_accuracy': accuracy,
            'predictions': y_pred
        }
        
        print(f"{name} Accuracy: {accuracy:.4f}")
    
    return results

# =============================================================================
# VISUALIZATION FUNCTIONS
# =============================================================================

def plot_model_comparison(baseline_results, gnn_results, save_path=None):
    """Plot comparison of model performances"""
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    
    # Prepare data
    model_names = list(baseline_results.keys()) + ['Best GNN']
    accuracies = [results['test_accuracy'] for results in baseline_results.values()] + [gnn_results['test_accuracy']]
    
    # Create colors
    colors = ['skyblue'] * len(baseline_results) + ['orange']
    
    # Create bar plot
    bars = ax.bar(model_names, accuracies, color=colors, alpha=0.7, edgecolor='black')
    
    # Add value labels on bars
    for bar, acc in zip(bars, accuracies):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,
                f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')
    
    ax.set_ylabel('Test Accuracy', fontsize=12)
    ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')
    ax.set_ylim(0, max(accuracies) * 1.1)
    
    # Rotate x-axis labels for better readability
    plt.xticks(rotation=45, ha='right')
    
    # Add grid
    ax.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"‚úÖ Model comparison plot saved to {save_path}")
    
    plt.show()
    return fig

def plot_training_history(train_losses, val_accuracies, save_path=None):
    """Plot training history"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Plot training loss
    ax1.plot(train_losses, 'b-', linewidth=2, label='Training Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Training Loss Over Time')
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    
    # Plot validation accuracy
    ax2.plot(val_accuracies, 'r-', linewidth=2, label='Validation Accuracy')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.set_title('Validation Accuracy Over Time')
    ax2.grid(True, alpha=0.3)
    ax2.legend()
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"‚úÖ Training history plot saved to {save_path}")
    
    plt.show()
    return fig

def plot_confusion_matrix(y_true, y_pred, class_names, save_path=None):
    """Plot confusion matrix"""
    cm = confusion_matrix(y_true, y_pred)
    
    fig, ax = plt.subplots(1, 1, figsize=(10, 8))
    
    # Create heatmap
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, yticklabels=class_names, ax=ax)
    
    ax.set_xlabel('Predicted Label', fontsize=12)
    ax.set_ylabel('True Label', fontsize=12)
    ax.set_title('Confusion Matrix', fontsize=14, fontweight='bold')
    
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"‚úÖ Confusion matrix plot saved to {save_path}")
    
    plt.show()
    return fig

# =============================================================================
# MAIN EXECUTION
# =============================================================================

def main():
    """Main execution function"""
    print("="*60)
    print("AgroGraphNet: Model Development")
    print("="*60)
    
    # 1. Load or create data
    try:
        print("Loading engineered features...")
        feature_file = PROCESSED_DATA_DIR / 'engineered_features.pkl'
        
        if not feature_file.exists():
            print("Engineered features not found. Creating sample data...")
            feature_data, summary_stats = create_sample_data()
        else:
            with open(feature_file, 'rb') as f:
                feature_data = pickle.load(f)
            
            with open(PROCESSED_DATA_DIR / 'feature_summary.json', 'r') as f:
                summary_stats = json.load(f)
        
        # Extract data
        node_features_by_time = feature_data['node_features_by_time']
        labels_by_time = feature_data['labels_by_time']
        edge_features_by_time = feature_data['edge_features_by_time']
        selected_features = feature_data['selected_features']
        time_points = feature_data['time_points']
        farms_df = feature_data['farms_df']
        distance_matrix = feature_data['distance_matrix']
        
        print(f"‚úÖ Loaded data with {len(time_points)} time points and {len(farms_df)} farms")
        
    except Exception as e:
        print(f"Error loading data: {e}")
        return
    
    # 2. Create graphs
    try:
        print("\nCreating PyTorch Geometric graphs...")
        
        # Create adjacency matrix
        adjacency_matrix = create_adjacency_matrix(
            distance_matrix,
            threshold_km=GRAPH_CONFIG['distance_threshold_km'],
            min_neighbors=GRAPH_CONFIG['min_neighbors'],
            max_neighbors=GRAPH_CONFIG['max_neighbors']
        )
        
        print(f"‚úÖ Adjacency matrix created: {adjacency_matrix.shape}")
        
        # Create graphs for each time point
        graphs = []
        for i, time_point in enumerate(time_points):
            node_features = node_features_by_time[time_point]
            labels = labels_by_time[time_point]
            edge_features = edge_features_by_time[time_point]
            
            # Create NetworkX graph
            G = create_networkx_graph(adjacency_matrix, node_features, edge_features, farms_df)
            
            # Convert to PyTorch Geometric
            data = networkx_to_pytorch_geometric(G, labels)
            data.time_point = time_point
            
            graphs.append(data)
        
        print(f"‚úÖ Created {len(graphs)} PyTorch Geometric graphs")
        
    except Exception as e:
        print(f"Error creating graphs: {e}")
        return
    
    # 3. Data splitting
    try:
        print("\nSplitting data...")
        
        # Temporal split
        n_time_points = len(graphs)
        train_end = int(0.6 * n_time_points)
        val_end = int(0.8 * n_time_points)
        
        train_graphs = graphs[:train_end]
        val_graphs = graphs[train_end:val_end]
        test_graphs = graphs[val_end:]
        
        # Create data loaders
        batch_size = MODEL_CONFIG['batch_size']
        train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)
        val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)
        test_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)
        
        print(f"‚úÖ Data split: {len(train_graphs)} train, {len(val_graphs)} val, {len(test_graphs)} test")
        
    except Exception as e:
        print(f"Error splitting data: {e}")
        return
    
    # 4. Train baseline models
    try:
        print("\nTraining baseline models...")
        
        # Prepare data for baseline models
        X_train = torch.cat([data.x for data in train_graphs]).numpy()
        y_train = torch.cat([data.y for data in train_graphs]).numpy()
        X_test = torch.cat([data.x for data in test_graphs]).numpy()
        y_test = torch.cat([data.y for data in test_graphs]).numpy()
        
        baseline_results = create_baseline_models(X_train, y_train, X_test, y_test)
        
        print("‚úÖ Baseline models trained")
        
    except Exception as e:
        print(f"Error training baseline models: {e}")
        return
    
    # 5. Train GNN models
    try:
        print("\nTraining GNN models...")
        
        # Model parameters
        input_dim = graphs[0].x.shape[1]
        hidden_dim = MODEL_CONFIG['hidden_dim']
        output_dim = len(DISEASE_CLASSES)
        num_layers = MODEL_CONFIG['num_layers']
        dropout = MODEL_CONFIG['dropout']
        learning_rate = MODEL_CONFIG['learning_rate']
        num_epochs = MODEL_CONFIG['num_epochs']
        early_stopping_patience = MODEL_CONFIG['early_stopping_patience']
        
        gnn_results = {}
        
        # Train GCN
        print("\nTraining GCN...")
        gcn_model = GCNModel(input_dim, hidden_dim, output_dim, num_layers, dropout)
        gcn_results = train_and_evaluate(
            gcn_model, train_loader, val_loader, test_loader,
            num_epochs, learning_rate, early_stopping_patience, device
        )
        gnn_results['GCN'] = gcn_results
        
        # Train GraphSAGE
        print("\nTraining GraphSAGE...")
        sage_model = GraphSAGEModel(input_dim, hidden_dim, output_dim, num_layers, dropout)
        sage_results = train_and_evaluate(
            sage_model, train_loader, val_loader, test_loader,
            num_epochs, learning_rate, early_stopping_patience, device
        )
        gnn_results['GraphSAGE'] = sage_results
        
        # Train GAT
        print("\nTraining GAT...")
        gat_model = GATModel(input_dim, hidden_dim, output_dim, num_layers, dropout)
        gat_results = train_and_evaluate(
            gat_model, train_loader, val_loader, test_loader,
            num_epochs, learning_rate, early_stopping_patience, device
        )
        gnn_results['GAT'] = gat_results
        
        print("‚úÖ All GNN models trained successfully!")
        
    except Exception as e:
        print(f"Error training GNN models: {e}")
        return
    
    # 6. Model comparison and results
    try:
        print("\nComparing model results...")
        
        # Combine baseline and GNN results
        all_results = {}
        
        # Add baseline results
        for model_name, results in baseline_results.items():
            all_results[model_name] = {
                'test_accuracy': results['test_accuracy'],
                'model_type': 'Baseline'
            }
        
        # Add GNN results
        for model_name, results in gnn_results.items():
            all_results[model_name] = {
                'test_accuracy': results['test_accuracy'],
                'model_type': 'GNN'
            }
        
        # Create comparison DataFrame
        comparison_df = pd.DataFrame([
            {'Model': name, 'Test Accuracy': results['test_accuracy'], 'Type': results['model_type']}
            for name, results in all_results.items()
        ]).sort_values('Test Accuracy', ascending=False)
        
        print("\nModel Performance Comparison:")
        print("=" * 60)
        print(comparison_df.to_string(index=False))
        
        # Find best models
        best_model_name = comparison_df.iloc[0]['Model']
        best_accuracy = comparison_df.iloc[0]['Test Accuracy']
        
        best_gnn = max(gnn_results.items(), key=lambda x: x[1]['test_accuracy'])
        best_gnn_name, best_gnn_results = best_gnn
        
        print(f"\nüèÜ Best Overall Model: {best_model_name} (Accuracy: {best_accuracy:.4f})")
        print(f"ü•á Best GNN Model: {best_gnn_name} (Accuracy: {best_gnn_results['test_accuracy']:.4f})")
        
    except Exception as e:
        print(f"Error in model comparison: {e}")
        return
    
    # 7. Create visualizations
    try:
        print("\nCreating visualizations...")
        
        # Model comparison plot
        fig1 = plot_model_comparison(
            baseline_results, 
            best_gnn_results,
            save_path=str(RESULTS_DIR / 'model_comparison.png')
        )
        
        # Training history for best GNN model
        if 'train_losses' in best_gnn_results and 'val_accuracies' in best_gnn_results:
            fig2 = plot_training_history(
                best_gnn_results['train_losses'],
                best_gnn_results['val_accuracies'],
                save_path=str(RESULTS_DIR / f'{best_gnn_name}_training_history.png')
            )
        
        # Confusion matrix for best GNN model
        if 'test_labels' in best_gnn_results and 'test_predictions' in best_gnn_results:
            class_names = list(DISEASE_CLASSES.values())
            fig3 = plot_confusion_matrix(
                best_gnn_results['test_labels'],
                best_gnn_results['test_predictions'],
                class_names=class_names,
                save_path=str(RESULTS_DIR / f'{best_gnn_name}_confusion_matrix.png')
            )
        
        print("‚úÖ Visualizations created and saved")
        
    except Exception as e:
        print(f"Error creating visualizations: {e}")
    
    # 8. Detailed analysis of best model
    try:
        print(f"\nDetailed Analysis of {best_gnn_name} Model:")
        print("=" * 50)
        
        # Classification report
        if 'classification_report' in best_gnn_results:
            report = best_gnn_results['classification_report']
            
            print("\nClassification Report:")
            class_names = list(DISEASE_CLASSES.values())
            
            # Create detailed report DataFrame
            report_data = []
            for class_name in class_names:
                if class_name in report:
                    report_data.append({
                        'Class': class_name,
                        'Precision': report[class_name]['precision'],
                        'Recall': report[class_name]['recall'],
                        'F1-Score': report[class_name]['f1-score'],
                        'Support': report[class_name]['support']
                    })
            
            if report_data:
                report_df = pd.DataFrame(report_data)
                print(report_df.to_string(index=False, float_format='%.3f'))
                
                # Overall metrics
                if 'macro avg' in report:
                    print(f"\nMacro Average:")
                    print(f"- Precision: {report['macro avg']['precision']:.3f}")
                    print(f"- Recall: {report['macro avg']['recall']:.3f}")
                    print(f"- F1-Score: {report['macro avg']['f1-score']:.3f}")
                
                if 'weighted avg' in report:
                    print(f"\nWeighted Average:")
                    print(f"- Precision: {report['weighted avg']['precision']:.3f}")
                    print(f"- Recall: {report['weighted avg']['recall']:.3f}")
                    print(f"- F1-Score: {report['weighted avg']['f1-score']:.3f}")
        
        # Performance by disease class
        if 'test_labels' in best_gnn_results and 'test_predictions' in best_gnn_results:
            test_labels = best_gnn_results['test_labels']
            test_predictions = best_gnn_results['test_predictions']
            
            print(f"\nPer-Class Accuracy:")
            for class_idx, class_name in DISEASE_CLASSES.items():
                class_mask = test_labels == class_idx
                if class_mask.sum() > 0:
                    class_accuracy = (test_predictions[class_mask] == test_labels[class_mask]).mean()
                    print(f"- {class_name}: {class_accuracy:.3f} ({class_mask.sum()} samples)")
        
        print("\n‚úÖ Detailed analysis completed")
        
    except Exception as e:
        print(f"Error in detailed analysis: {e}")
    
    # 9. Save models and results
    try:
        print("\nSaving models and results...")
        
        # Save best GNN model
        best_model_path = MODELS_DIR / f'best_{best_gnn_name.lower()}_model.pth'
        torch.save(best_gnn_results['model_state_dict'], best_model_path)
        print(f"‚úÖ Best model saved to {best_model_path}")
        
        # Save all results
        results_data = {
            'baseline_results': baseline_results,
            'gnn_results': gnn_results,
            'best_model_name': best_gnn_name,
            'best_model_accuracy': best_gnn_results['test_accuracy'],
            'model_comparison': comparison_df.to_dict('records'),
            'model_config': MODEL_CONFIG,
            'graph_config': GRAPH_CONFIG
        }
        
        with open(RESULTS_DIR / 'model_results.pkl', 'wb') as f:
            pickle.dump(results_data, f)
        
        print(f"‚úÖ Results saved to {RESULTS_DIR / 'model_results.pkl'}")
        
        # Save model summary as JSON
        summary_data = {
            'best_model': best_gnn_name,
            'best_accuracy': float(best_gnn_results['test_accuracy']),
            'model_comparison': {
                name: float(results['test_accuracy']) 
                for name, results in all_results.items()
            },
            'training_config': MODEL_CONFIG,
            'dataset_info': summary_stats
        }
        
        with open(RESULTS_DIR / 'model_summary.json', 'w') as f:
            json.dump(summary_data, f, indent=2)
        
        print(f"‚úÖ Model summary saved to {RESULTS_DIR / 'model_summary.json'}")
        
        # Save graphs for future use
        graph_data = {
            'graphs': graphs,
            'train_indices': list(range(len(train_graphs))),
            'val_indices': list(range(len(train_graphs), len(train_graphs) + len(val_graphs))),
            'test_indices': list(range(len(train_graphs) + len(val_graphs), len(graphs))),
            'adjacency_matrix': adjacency_matrix,
            'time_points': time_points
        }
        
        with open(PROCESSED_DATA_DIR / 'pytorch_graphs.pkl', 'wb') as f:
            pickle.dump(graph_data, f)
        
        print(f"‚úÖ Graph data saved to {PROCESSED_DATA_DIR / 'pytorch_graphs.pkl'}")
        
    except Exception as e:
        print(f"Error saving results: {e}")
    
    # 10. Final summary
    print("\n" + "="*60)
    print("üéâ Model development completed successfully!")
    print("="*60)
    print("\nFinal Results Summary:")
    print(f"- Best Overall Model: {best_model_name} (Accuracy: {best_accuracy:.4f})")
    print(f"- Best GNN Model: {best_gnn_name} (Accuracy: {best_gnn_results['test_accuracy']:.4f})")
    
    best_baseline_acc = max(baseline_results.values(), key=lambda x: x['test_accuracy'])['test_accuracy']
    improvement = best_gnn_results['test_accuracy'] - best_baseline_acc
    print(f"- GNN improvement over best baseline: {improvement:.4f}")
    
    print(f"\nModel Comparison Summary:")
    for _, row in comparison_df.iterrows():
        print(f"- {row['Model']}: {row['Test Accuracy']:.4f} ({row['Type']})")
    
    print("\nFiles Created:")
    print(f"- Best model: {best_model_path}")
    print(f"- Results: {RESULTS_DIR / 'model_results.pkl'}")
    print(f"- Summary: {RESULTS_DIR / 'model_summary.json'}")
    print(f"- Graphs: {PROCESSED_DATA_DIR / 'pytorch_graphs.pkl'}")
    print(f"- Visualizations: {RESULTS_DIR}/")
    
    print("\nNext steps:")
    print("1. Analyze the generated visualizations")
    print("2. Fine-tune hyperparameters if needed")
    print("3. Create prediction maps and detailed reports")
    print("4. Deploy the best model for inference")

# Additional utility functions for enhanced functionality

def load_saved_model(model_class, model_path, input_dim, hidden_dim, output_dim, num_layers=3, dropout=0.3):
    """Load a saved model"""
    model = model_class(input_dim, hidden_dim, output_dim, num_layers, dropout)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    return model

def predict_with_model(model, data_loader, device='cpu'):
    """Make predictions with a trained model"""
    model.eval()
    predictions = []
    probabilities = []
    
    with torch.no_grad():
        for batch in data_loader:
            batch = batch.to(device)
            out = model(batch.x, batch.edge_index, batch.batch)
            pred = out.argmax(dim=1)
            prob = torch.exp(out)  # Convert from log probabilities
            
            predictions.extend(pred.cpu().numpy())
            probabilities.extend(prob.cpu().numpy())
    
    return np.array(predictions), np.array(probabilities)

def analyze_model_performance(y_true, y_pred, class_names):
    """Comprehensive model performance analysis"""
    from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
    
    # Basic metrics
    accuracy = accuracy_score(y_true, y_pred)
    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average=None)
    
    # Per-class analysis
    results = {
        'overall_accuracy': accuracy,
        'per_class_metrics': {}
    }
    
    for i, class_name in enumerate(class_names):
        results['per_class_metrics'][class_name] = {
            'precision': precision[i],
            'recall': recall[i],
            'f1_score': f1[i],
            'support': support[i]
        }
    
    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    results['confusion_matrix'] = cm
    
    return results

def create_prediction_summary(predictions, probabilities, time_points, farms_df, disease_classes):
    """Create a summary of predictions"""
    summary_data = []
    
    for i, (pred, prob, time_point) in enumerate(zip(predictions, probabilities, time_points)):
        farm_info = farms_df.iloc[i % len(farms_df)]
        
        summary_data.append({
            'time_point': time_point,
            'farm_id': farm_info['farm_id'],
            'latitude': farm_info['latitude'],
            'longitude': farm_info['longitude'],
            'predicted_disease': disease_classes[pred],
            'confidence': prob[pred],
            'probabilities': {disease_classes[j]: prob[j] for j in range(len(disease_classes))}
        })
    
    return pd.DataFrame(summary_data)

# Run the main function if script is executed directly
if __name__ == "__main__":
    main()