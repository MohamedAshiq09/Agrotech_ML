{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgroGraphNet: Model Development\n",
    "\n",
    "This notebook develops and trains Graph Neural Network models for crop disease prediction.\n",
    "\n",
    "## Objectives:\n",
    "1. Create PyTorch Geometric graphs from engineered features\n",
    "2. Implement and train different GNN architectures (GCN, GraphSAGE, GAT)\n",
    "3. Train baseline models for comparison\n",
    "4. Hyperparameter tuning and model selection\n",
    "5. Model evaluation and performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from config import *\n",
    "from graph_utils import *\n",
    "from model_utils import *\n",
    "from visualization import *\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load graph data from previous notebook\n",
    "print(\"Loading graph data...\")\n",
    "\n",
    "graph_file = GRAPHS_DIR / 'farm_graphs.pkl'\n",
    "if graph_file.exists():\n",
    "    with open(graph_file, 'rb') as f:\n",
    "        graph_data = pickle.load(f)\n",
    "    \n",
    "    pytorch_graphs = graph_data['pytorch_graphs']\n",
    "    farms_df = graph_data['farms_df']\n",
    "    time_points = graph_data['time_points']\n",
    "    \n",
    "    print(f\"âœ… Loaded graph data: {len(pytorch_graphs)} graphs\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Graph data not found. Creating basic graphs from available data...\")\n",
    "    \n",
    "    # Load basic data and create simple graphs\n",
    "    farm_files = list(FARM_LOCATIONS_DIR.glob('*.csv'))\n",
    "    if not farm_files:\n",
    "        raise FileNotFoundError(\"No farm data found. Please run previous notebooks first.\")\n",
    "    \n",
    "    farms_df = pd.read_csv(farm_files[0])\n",
    "    \n",
    "    # Create basic graphs\n",
    "    pytorch_graphs = create_basic_graphs(farms_df)\n",
    "    time_points = [f\"2023-{i+1:02d}-01\" for i in range(len(pytorch_graphs))]\n",
    "    \n",
    "    print(f\"âœ… Created basic graphs: {len(pytorch_graphs)} graphs\")\n",
    "\n",
    "# Display graph information\n",
    "sample_graph = pytorch_graphs[0]\n",
    "print(f\"\\nGraph information:\")\n",
    "print(f\"- Number of graphs: {len(pytorch_graphs)}\")\n",
    "print(f\"- Nodes per graph: {sample_graph.x.shape[0]}\")\n",
    "print(f\"- Node features: {sample_graph.x.shape[1]}\")\n",
    "print(f\"- Edges per graph: {sample_graph.edge_index.shape[1]}\")\n",
    "print(f\"- Classes: {len(torch.unique(sample_graph.y))}\")\n",
    "print(f\"- Class distribution: {torch.bincount(sample_graph.y).tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_graphs(farms_df, num_time_points=12):\n",
    "    \"\"\"\n",
    "    Create basic graphs when processed data is not available\n",
    "    \"\"\"\n",
    "    print(\"Creating basic graphs...\")\n",
    "    \n",
    "    graphs = []\n",
    "    \n",
    "    # Create distance matrix\n",
    "    distance_matrix = create_distance_matrix(farms_df)\n",
    "    \n",
    "    # Create adjacency matrix\n",
    "    adjacency_matrix = create_adjacency_matrix(distance_matrix, threshold_km=5.0)\n",
    "    \n",
    "    for t in range(num_time_points):\n",
    "        # Create basic node features\n",
    "        node_features = []\n",
    "        labels = []\n",
    "        \n",
    "        for _, farm in farms_df.iterrows():\n",
    "            # Basic features: lat, lon, area, crop type (one-hot)\n",
    "            features = [farm['lat'], farm['lon'], farm['area_hectares']]\n",
    "            \n",
    "            # Add crop type one-hot encoding\n",
    "            crop_types = farms_df['crop_type'].unique()\n",
    "            for crop in crop_types:\n",
    "                features.append(1.0 if farm['crop_type'] == crop else 0.0)\n",
    "            \n",
    "            # Add temporal features\n",
    "            features.extend([t / num_time_points, np.sin(2 * np.pi * t / 12), np.cos(2 * np.pi * t / 12)])\n",
    "            \n",
    "            # Add some random environmental features\n",
    "            features.extend(np.random.normal(0, 1, 5))\n",
    "            \n",
    "            node_features.append(features)\n",
    "            \n",
    "            # Random disease labels with higher probability of healthy\n",
    "            label = np.random.choice([0, 1, 2, 3, 4], p=[0.7, 0.1, 0.1, 0.05, 0.05])\n",
    "            labels.append(label)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "        y = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        # Create edge index from adjacency matrix\n",
    "        edge_indices = np.where(adjacency_matrix == 1)\n",
    "        edge_index = torch.tensor([edge_indices[0], edge_indices[1]], dtype=torch.long)\n",
    "        \n",
    "        # Create edge attributes (distances)\n",
    "        edge_attr = []\n",
    "        for i in range(edge_index.shape[1]):\n",
    "            src, dst = edge_index[0, i].item(), edge_index[1, i].item()\n",
    "            dist = distance_matrix[src, dst]\n",
    "            edge_attr.append([dist, 1.0])  # distance and similarity\n",
    "        \n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "        \n",
    "        # Create PyTorch Geometric data object\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "        graphs.append(data)\n",
    "    \n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/validation/test sets\n",
    "print(\"Splitting data into train/validation/test sets...\")\n",
    "\n",
    "# Temporal split: use first 60% for training, next 20% for validation, last 20% for testing\n",
    "n_time_points = len(pytorch_graphs)\n",
    "train_end = int(0.6 * n_time_points)\n",
    "val_end = int(0.8 * n_time_points)\n",
    "\n",
    "train_graphs = pytorch_graphs[:train_end]\n",
    "val_graphs = pytorch_graphs[train_end:val_end]\n",
    "test_graphs = pytorch_graphs[val_end:]\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"- Training: {len(train_graphs)} time points\")\n",
    "print(f\"- Validation: {len(val_graphs)} time points\")\n",
    "print(f\"- Testing: {len(test_graphs)} time points\")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = MODEL_CONFIG['batch_size']\n",
    "\n",
    "train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"\\nâœ… Data loaders created with batch size: {batch_size}\")\n",
    "\n",
    "# Check class distribution\n",
    "train_labels = torch.cat([data.y for data in train_graphs])\n",
    "val_labels = torch.cat([data.y for data in val_graphs])\n",
    "test_labels = torch.cat([data.y for data in test_graphs])\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"Training: {torch.bincount(train_labels).tolist()}\")\n",
    "print(f\"Validation: {torch.bincount(val_labels).tolist()}\")\n",
    "print(f\"Testing: {torch.bincount(test_labels).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline models for comparison\n",
    "print(\"Training baseline models...\")\n",
    "\n",
    "# Prepare data for baseline models (flatten temporal dimension)\n",
    "X_train = torch.cat([data.x for data in train_graphs]).numpy()\n",
    "y_train = torch.cat([data.y for data in train_graphs]).numpy()\n",
    "\n",
    "X_val = torch.cat([data.x for data in val_graphs]).numpy()\n",
    "y_val = torch.cat([data.y for data in val_graphs]).numpy()\n",
    "\n",
    "X_test = torch.cat([data.x for data in test_graphs]).numpy()\n",
    "y_test = torch.cat([data.y for data in test_graphs]).numpy()\n",
    "\n",
    "print(f\"Baseline data shapes:\")\n",
    "print(f\"- X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"- X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print(f\"- X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# Train baseline models\n",
    "baseline_results = create_baseline_models(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"\\nâœ… Baseline models trained\")\n",
    "print(\"\\nBaseline Results:\")\n",
    "for model_name, results in baseline_results.items():\n",
    "    print(f\"{model_name}: {results['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GNN Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train different GNN architectures\n",
    "print(\"Training GNN models...\")\n",
    "\n",
    "# Model parameters\n",
    "input_dim = pytorch_graphs[0].x.shape[1]\n",
    "hidden_dim = MODEL_CONFIG['hidden_dim']\n",
    "output_dim = len(DISEASE_CLASSES)\n",
    "num_layers = MODEL_CONFIG['num_layers']\n",
    "dropout = MODEL_CONFIG['dropout']\n",
    "learning_rate = MODEL_CONFIG['learning_rate']\n",
    "num_epochs = MODEL_CONFIG['num_epochs']\n",
    "early_stopping_patience = MODEL_CONFIG['early_stopping_patience']\n",
    "\n",
    "print(f\"Model configuration:\")\n",
    "print(f\"- Input dim: {input_dim}\")\n",
    "print(f\"- Hidden dim: {hidden_dim}\")\n",
    "print(f\"- Output dim: {output_dim}\")\n",
    "print(f\"- Num layers: {num_layers}\")\n",
    "print(f\"- Dropout: {dropout}\")\n",
    "print(f\"- Learning rate: {learning_rate}\")\n",
    "print(f\"- Epochs: {num_epochs}\")\n",
    "\n",
    "# Dictionary to store results\n",
    "gnn_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GCN model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training GCN Model\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "gcn_model = GCNModel(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "gcn_results = train_and_evaluate(\n",
    "    model=gcn_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    early_stopping_patience=early_stopping_patience,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "gnn_results['GCN'] = gcn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GraphSAGE model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training GraphSAGE Model\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "sage_model = GraphSAGEModel(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "sage_results = train_and_evaluate(\n",
    "    model=sage_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    early_stopping_patience=early_stopping_patience,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "gnn_results['GraphSAGE'] = sage_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GAT model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training GAT Model\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "gat_model = GATModel(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "gat_results = train_and_evaluate(\n",
    "    model=gat_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    early_stopping_patience=early_stopping_patience,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "gnn_results['GAT'] = gat_results\n",
    "\n",
    "print(\"\\nâœ… All GNN models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all model results\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine baseline and GNN results\n",
    "all_results = {}\n",
    "\n",
    "# Add baseline results\n",
    "for model_name, results in baseline_results.items():\n",
    "    all_results[model_name] = {\n",
    "        'test_accuracy': results['test_accuracy'],\n",
    "        'model_type': 'Baseline'\n",
    "    }\n",
    "\n",
    "# Add GNN results\n",
    "for model_name, results in gnn_results.items():\n",
    "    all_results[model_name] = {\n",
    "        'test_accuracy': results['test_accuracy'],\n",
    "        'model_type': 'GNN'\n",
    "    }\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame([\n",
    "    {'Model': name, 'Test Accuracy': results['test_accuracy'], 'Type': results['model_type']}\n",
    "    for name, results in all_results.items()\n",
    "]).sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_accuracy = comparison_df.iloc[0]['Test Accuracy']\n",
    "\n",
    "print(f\"\\nðŸ† Best Model: {best_model_name} (Accuracy: {best_accuracy:.4f})\")\n",
    "\n",
    "# Get best GNN model\n",
    "best_gnn = max(gnn_results.items(), key=lambda x: x[1]['test_accuracy'])\n",
    "best_gnn_name, best_gnn_results = best_gnn\n",
    "\n",
    "print(f\"ðŸ¥‡ Best GNN Model: {best_gnn_name} (Accuracy: {best_gnn_results['test_accuracy']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig = plot_model_comparison(\n",
    "    baseline_results, \n",
    "    best_gnn_results,\n",
    "    save_path=str(RESULTS_DIR / '05_model_comparison.png')\n",
    ")\n",
    "\n",
    "# Plot training history for best GNN model\n",
    "if 'train_losses' in best_gnn_results and 'val_accuracies' in best_gnn_results:\n",
    "    fig = plot_training_history(\n",
    "        best_gnn_results['train_losses'],\n",
    "        best_gnn_results['val_accuracies'],\n",
    "        save_path=str(RESULTS_DIR / f'05_{best_gnn_name}_training_history.png')\n",
    "    )\n",
    "\n",
    "# Plot confusion matrix for best GNN model\n",
    "if 'test_labels' in best_gnn_results and 'test_predictions' in best_gnn_results:\n",
    "    class_names = list(DISEASE_CLASSES.values())\n",
    "    fig = plot_confusion_matrix(\n",
    "        best_gnn_results['test_labels'],\n",
    "        best_gnn_results['test_predictions'],\n",
    "        class_names=class_names,\n",
    "        save_path=str(RESULTS_DIR / f'05_{best_gnn_name}_confusion_matrix.png')\n",
    "    )\n",
    "\n",
    "print(\"âœ… Visualizations created and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detailed Analysis of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of the best GNN model\n",
    "print(f\"Detailed Analysis of {best_gnn_name} Model:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Classification report\n",
    "if 'classification_report' in best_gnn_results:\n",
    "    report = best_gnn_results['classification_report']\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    class_names = list(DISEASE_CLASSES.values())\n",
    "    \n",
    "    # Create detailed report DataFrame\n",
    "    report_data = []\n",
    "    for class_name in class_names:\n",
    "        if class_name in report:\n",
    "            report_data.append({\n",
    "                'Class': class_name,\n",
    "                'Precision': report[class_name]['precision'],\n",
    "                'Recall': report[class_name]['recall'],\n",
    "                'F1-Score': report[class_name]['f1-score'],\n",
    "                'Support': report[class_name]['support']\n",
    "            })\n",
    "    \n",
    "    if report_data:\n",
    "        report_df = pd.DataFrame(report_data)\n",
    "        print(report_df.to_string(index=False, float_format='%.3f'))\n",
    "    \n",
    "    # Overall metrics\n",
    "    if 'macro avg' in report:\n",
    "        print(f\"\\nMacro Average:\")\n",
    "        print(f\"- Precision: {report['macro avg']['precision']:.3f}\")\n",
    "        print(f\"- Recall: {report['macro avg']['recall']:.3f}\")\n",
    "        print(f\"- F1-Score: {report['macro avg']['f1-score']:.3f}\")\n",
    "    \n",
    "    if 'weighted avg' in report:\n",
    "        print(f\"\\nWeighted Average:\")\n",
    "        print(f\"- Precision: {report['weighted avg']['precision']:.3f}\")\n",
    "        print(f\"- Recall: {report['weighted avg']['recall']:.3f}\")\n",
    "        print(f\"- F1-Score: {report['weighted avg']['f1-score']:.3f}\")\n",
    "\n",
    "# Performance by disease class\n",
    "if 'test_labels' in best_gnn_results and 'test_predictions' in best_gnn_results:\n",
    "    test_labels = best_gnn_results['test_labels']\n",
    "    test_predictions = best_gnn_results['test_predictions']\n",
    "    \n",
    "    print(f\"\\nPer-Class Accuracy:\")\n",
    "    for class_idx, class_name in DISEASE_CLASSES.items():\n",
    "        class_mask = test_labels == class_idx\n",
    "        if class_mask.sum() > 0:\n",
    "            class_accuracy = (test_predictions[class_mask] == test_labels[class_mask]).mean()\n",
    "            print(f\"- {class_name}: {class_accuracy:.3f} ({class_mask.sum()} samples)\")\n",
    "\n",
    "print(\"\\nâœ… Detailed analysis completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models and results\n",
    "print(\"Saving models and results...\")\n",
    "\n",
    "# Save best GNN model\n",
    "best_model_path = MODELS_DIR / f'best_{best_gnn_name.lower()}_model.pth'\n",
    "torch.save(best_gnn_results['model_state_dict'], best_model_path)\n",
    "print(f\"âœ… Best model saved to {best_model_path}\")\n",
    "\n",
    "# Save all results\n",
    "results_data = {\n",
    "    'baseline_results': baseline_results,\n",
    "    'gnn_results': gnn_results,\n",
    "    'best_model_name': best_gnn_name,\n",
    "    'best_model_accuracy': best_gnn_results['test_accuracy'],\n",
    "    'model_comparison': comparison_df.to_dict('records'),\n",
    "    'model_config': MODEL_CONFIG,\n",
    "    'graph_config': GRAPH_CONFIG\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'model_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results_data, f)\n",
    "\n",
    "print(f\"âœ… Results saved to {RESULTS_DIR / 'model_results.pkl'}\")\n",
    "\n",
    "# Save model summary as JSON\n",
    "summary_data = {\n",
    "    'best_model': best_gnn_name,\n",
    "    'best_accuracy': float(best_gnn_results['test_accuracy']),\n",
    "    'model_comparison': {\n",
    "        name: float(results['test_accuracy']) \n",
    "        for name, results in all_results.items()\n",
    "    },\n",
    "    'training_config': MODEL_CONFIG,\n",
    "    'num_graphs': len(pytorch_graphs),\n",
    "    'num_nodes': pytorch_graphs[0].x.shape[0],\n",
    "    'node_features': pytorch_graphs[0].x.shape[1]\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'model_summary.json', 'w') as f:\n",
    "    json.dump(summary_data, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Model summary saved to {RESULTS_DIR / 'model_summary.json'}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Model development completed successfully!\")\n",
    "print(\"\\nFinal Results Summary:\")\n",
    "print(f\"- Best Model: {best_gnn_name}\")\n",
    "print(f\"- Best Accuracy: {best_gnn_results['test_accuracy']:.4f}\")\n",
    "print(f\"- Improvement over best baseline: {best_gnn_results['test_accuracy'] - max(baseline_results.values(), key=lambda x: x['test_accuracy'])['test_accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run notebook 06_evaluation_visualization.ipynb\")\n",
    "print(\"2. Create detailed visualizations and analysis\")\n",
    "print(\"3. Generate prediction maps and reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
