{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgroGraphNet: End-to-End Prediction Pipeline\n",
    "\n",
    "This notebook creates an end-to-end prediction pipeline for real-time crop disease prediction.\n",
    "\n",
    "## Objectives:\n",
    "1. Load trained models and create inference pipeline\n",
    "2. Simulate real-time data ingestion\n",
    "3. Generate predictions for new data\n",
    "4. Create early warning system\n",
    "5. Build interactive dashboard\n",
    "6. Export results for stakeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import folium\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pickle\n",
    "import json\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from config import *\n",
    "from model_utils import *\n",
    "from graph_utils import *\n",
    "from data_utils import *\n",
    "from visualization import *\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}  
},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trained Models and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained models and data\n",
    "print(\"Loading trained models and data...\")\n",
    "\n",
    "# Load model results\n",
    "results_file = RESULTS_DIR / 'model_results.pkl'\n",
    "if results_file.exists():\n",
    "    with open(results_file, 'rb') as f:\n",
    "        results_data = pickle.load(f)\n",
    "    \n",
    "    best_model_name = results_data['best_model_name']\n",
    "    best_model_accuracy = results_data['best_model_accuracy']\n",
    "    \n",
    "    print(f\"✅ Best model: {best_model_name} (Accuracy: {best_model_accuracy:.4f})\")\n",
    "else:\n",
    "    print(\"⚠️ Model results not found. Using default settings.\")\n",
    "    best_model_name = 'GCN'\n",
    "    best_model_accuracy = 0.85\n",
    "\n",
    "# Load farm data\n",
    "farm_files = list(FARM_LOCATIONS_DIR.glob('*.csv'))\n",
    "if farm_files:\n",
    "    farms_df = pd.read_csv(farm_files[0])\n",
    "    print(f\"✅ Loaded farm data: {len(farms_df)} farms\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Farm data not found. Please run previous notebooks first.\")\n",
    "\n",
    "# Load feature scaler if available\n",
    "scaler_file = PROCESSED_DATA_DIR / 'feature_scaler.pkl'\n",
    "if scaler_file.exists():\n",
    "    scaler = joblib.load(scaler_file)\n",
    "    print(\"✅ Loaded feature scaler\")\n",
    "else:\n",
    "    print(\"⚠️ Feature scaler not found. Will create basic scaler.\")\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "print(\"\\n✅ Data loading completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Prediction Pipeline Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgroGraphNetPipeline:\n",
    "    \"\"\"\n",
    "    End-to-end prediction pipeline for AgroGraphNet\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, farms_df, scaler, device='cpu'):\n",
    "        self.farms_df = farms_df\n",
    "        self.scaler = scaler\n",
    "        self.device = device\n",
    "        self.disease_classes = DISEASE_CLASSES\n",
    "        \n",
    "        # Load trained model\n",
    "        self.model = self.load_model(model_path)\n",
    "        \n",
    "        # Create distance matrix for graph construction\n",
    "        self.distance_matrix = create_distance_matrix(farms_df)\n",
    "        self.adjacency_matrix = create_adjacency_matrix(self.distance_matrix)\n",
    "        \n",
    "        print(f\"✅ Pipeline initialized with {len(farms_df)} farms\")\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"\n",
    "        Load the trained model\n",
    "        \"\"\"\n",
    "        if not Path(model_path).exists():\n",
    "            print(f\"⚠️ Model file not found: {model_path}\")\n",
    "            print(\"Creating dummy model for demonstration...\")\n",
    "            \n",
    "            # Create dummy model\n",
    "            input_dim = 20  # Estimated feature dimension\n",
    "            hidden_dim = MODEL_CONFIG['hidden_dim']\n",
    "            output_dim = len(DISEASE_CLASSES)\n",
    "            \n",
    "            model = GCNModel(input_dim, hidden_dim, output_dim)\n",
    "            return model.to(self.device)\n",
    "        \n",
    "        # Load actual trained model\n",
    "        input_dim = 20  # This should match your actual feature dimension\n",
    "        hidden_dim = MODEL_CONFIG['hidden_dim']\n",
    "        output_dim = len(DISEASE_CLASSES)\n",
    "        \n",
    "        if 'gcn' in str(model_path).lower():\n",
    "            model = GCNModel(input_dim, hidden_dim, output_dim)\n",
    "        elif 'sage' in str(model_path).lower():\n",
    "            model = GraphSAGEModel(input_dim, hidden_dim, output_dim)\n",
    "        elif 'gat' in str(model_path).lower():\n",
    "            model = GATModel(input_dim, hidden_dim, output_dim)\n",
    "        else:\n",
    "            model = GCNModel(input_dim, hidden_dim, output_dim)\n",
    "        \n",
    "        try:\n",
    "            model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "            print(f\"✅ Loaded trained model from {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error loading model: {e}\")\n",
    "            print(\"Using randomly initialized model for demonstration\")\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def preprocess_data(self, weather_data, satellite_data=None):\n",
    "        \"\"\"\n",
    "        Preprocess input data for prediction\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        \n",
    "        for _, farm in self.farms_df.iterrows():\n",
    "            farm_features = []\n",
    "            \n",
    "            # Basic farm features\n",
    "            farm_features.extend([farm['lat'], farm['lon'], farm['area_hectares']])\n",
    "            \n",
    "            # Crop type (one-hot encoded)\n",
    "            crop_types = self.farms_df['crop_type'].unique()\n",
    "            for crop in crop_types:\n",
    "                farm_features.append(1.0 if farm['crop_type'] == crop else 0.0)\n",
    "            \n",
    "            # Weather features\n",
    "            farm_weather = weather_data[\n",
    "                (abs(weather_data['lat'] - farm['lat']) < 0.01) & \n",
    "                (abs(weather_data['lon'] - farm['lon']) < 0.01)\n",
    "            ]\n",
    "            \n",
    "            if len(farm_weather) > 0:\n",
    "                farm_features.extend([\n",
    "                    farm_weather['temperature'].mean(),\n",
    "                    farm_weather['humidity'].mean(),\n",
    "                    farm_weather['precipitation'].mean(),\n",
    "                    farm_weather['wind_speed'].mean()\n",
    "                ])\n",
    "            else:\n",
    "                # Use overall averages\n",
    "                farm_features.extend([\n",
    "                    weather_data['temperature'].mean(),\n",
    "                    weather_data['humidity'].mean(),\n",
    "                    weather_data['precipitation'].mean(),\n",
    "                    weather_data['wind_speed'].mean()\n",
    "                ])\n",
    "            \n",
    "            # Satellite features (if available)\n",
    "            if satellite_data is not None:\n",
    "                # Add NDVI, EVI, etc.\n",
    "                farm_features.extend([0.7, 0.6, 0.5])  # Dummy values\n",
    "            else:\n",
    "                # Use default vegetation indices\n",
    "                farm_features.extend([0.7, 0.6, 0.5])\n",
    "            \n",
    "            # Temporal features\n",
    "            current_time = datetime.now()\n",
    "            month = current_time.month\n",
    "            farm_features.extend([\n",
    "                month / 12.0,\n",
    "                np.sin(2 * np.pi * month / 12),\n",
    "                np.cos(2 * np.pi * month / 12)\n",
    "            ])\n",
    "            \n",
    "            # Pad or truncate to expected dimension\n",
    "            while len(farm_features) < 20:\n",
    "                farm_features.append(0.0)\n",
    "            farm_features = farm_features[:20]\n",
    "            \n",
    "            features.append(farm_features)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def create_graph(self, node_features):\n",
    "        \"\"\"\n",
    "        Create PyTorch Geometric graph from node features\n",
    "        \"\"\"\n",
    "        # Convert to tensor\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "        \n",
    "        # Create edge index from adjacency matrix\n",
    "        edge_indices = np.where(self.adjacency_matrix == 1)\n",
    "        edge_index = torch.tensor([edge_indices[0], edge_indices[1]], dtype=torch.long)\n",
    "        \n",
    "        # Create edge attributes\n",
    "        edge_attr = []\n",
    "        for i in range(edge_index.shape[1]):\n",
    "            src, dst = edge_index[0, i].item(), edge_index[1, i].item()\n",
    "            dist = self.distance_matrix[src, dst]\n",
    "            edge_attr.append([dist, 1.0])  # distance and similarity\n",
    "        \n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "        \n",
    "        # Create PyTorch Geometric data object\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        return data.to(self.device)\n",
    "    \n",
    "    def predict(self, weather_data, satellite_data=None):\n",
    "        \"\"\"\n",
    "        Make predictions for all farms\n",
    "        \"\"\"\n",
    "        # Preprocess data\n",
    "        node_features = self.preprocess_data(weather_data, satellite_data)\n",
    "        \n",
    "        # Create graph\n",
    "        graph = self.create_graph(node_features)\n",
    "        \n",
    "        # Make predictions\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = self.model(graph.x, graph.edge_index)\n",
    "            probabilities = torch.softmax(output, dim=1)\n",
    "            predictions = output.argmax(dim=1)\n",
    "        \n",
    "        # Convert to numpy\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        probabilities = probabilities.cpu().numpy()\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results = []\n",
    "        for i, (_, farm) in enumerate(self.farms_df.iterrows()):\n",
    "            pred_class = predictions[i]\n",
    "            confidence = probabilities[i].max()\n",
    "            \n",
    "            results.append({\n",
    "                'farm_id': farm['farm_id'],\n",
    "                'lat': farm['lat'],\n",
    "                'lon': farm['lon'],\n",
    "                'crop_type': farm['crop_type'],\n",
    "                'predicted_disease': self.disease_classes[pred_class],\n",
    "                'confidence': confidence,\n",
    "                'risk_level': self.get_risk_level(pred_class, confidence),\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def get_risk_level(self, prediction, confidence):\n",
    "        \"\"\"\n",
    "        Determine risk level based on prediction and confidence\n",
    "        \"\"\"\n",
    "        if prediction == 0:  # Healthy\n",
    "            return 'Low'\n",
    "        elif confidence > 0.8:\n",
    "            return 'High'\n",
    "        elif confidence > 0.6:\n",
    "            return 'Medium'\n",
    "        else:\n",
    "            return 'Low'\n",
    "\n",
    "print(\"✅ Pipeline class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the prediction pipeline\n",
    "print(\"Initializing prediction pipeline...\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model path\n",
    "model_path = MODELS_DIR / f'best_{best_model_name.lower()}_model.pth'\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = AgroGraphNetPipeline(\n",
    "    model_path=model_path,\n",
    "    farms_df=farms_df,\n",
    "    scaler=scaler,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"✅ Pipeline initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulate Real-time Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate real-time weather data\n",
    "print(\"Simulating real-time weather data...\")\n",
    "\n",
    "def generate_weather_data(farms_df, date=None):\n",
    "    \"\"\"\n",
    "    Generate simulated weather data for all farm locations\n",
    "    \"\"\"\n",
    "    if date is None:\n",
    "        date = datetime.now()\n",
    "    \n",
    "    weather_data = []\n",
    "    \n",
    "    for _, farm in farms_df.iterrows():\n",
    "        # Simulate weather with some seasonal variation\n",
    "        month = date.month\n",
    "        \n",
    "        # Temperature varies by season\n",
    "        base_temp = 20 + 10 * np.sin(2 * np.pi * (month - 3) / 12)\n",
    "        temperature = base_temp + np.random.normal(0, 5)\n",
    "        \n",
    "        # Humidity\n",
    "        humidity = np.random.uniform(40, 80)\n",
    "        \n",
    "        # Precipitation (higher in certain months)\n",
    "        precip_factor = 1 + 0.5 * np.sin(2 * np.pi * (month - 6) / 12)\n",
    "        precipitation = np.random.exponential(2) * precip_factor\n",
    "        \n",
    "        # Wind speed\n",
    "        wind_speed = np.random.uniform(2, 15)\n",
    "        \n",
    "        weather_data.append({\n",
    "            'lat': farm['lat'],\n",
    "            'lon': farm['lon'],\n",
    "            'temperature': temperature,\n",
    "            'humidity': humidity,\n",
    "            'precipitation': precipitation,\n",
    "            'wind_speed': wind_speed,\n",
    "            'timestamp': date.isoformat()\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(weather_data)\n",
    "\n",
    "# Generate current weather data\n",
    "current_weather = generate_weather_data(farms_df)\n",
    "print(f\"✅ Generated weather data for {len(current_weather)} locations\")\n",
    "\n",
    "# Display sample weather data\n",
    "print(\"\\nSample weather data:\")\n",
    "display(current_weather.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the pipeline\n",
    "print(\"Making disease predictions...\")\n",
    "\n",
    "predictions = pipeline.predict(current_weather)\n",
    "\n",
    "print(f\"✅ Generated predictions for {len(predictions)} farms\")\n",
    "\n",
    "# Display prediction summary\n",
    "print(\"\\nPrediction Summary:\")\n",
    "disease_counts = predictions['predicted_disease'].value_counts()\n",
    "risk_counts = predictions['risk_level'].value_counts()\n",
    "\n",
    "print(\"\\nDisease Distribution:\")\n",
    "for disease, count in disease_counts.items():\n",
    "    percentage = count / len(predictions) * 100\n",
    "    print(f\"- {disease}: {count} farms ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nRisk Level Distribution:\")\n",
    "for risk, count in risk_counts.items():\n",
    "    percentage = count / len(predictions) * 100\n",
    "    print(f\"- {risk}: {count} farms ({percentage:.1f}%)\")\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "display(predictions.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Early Warning System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create early warning system\n",
    "print(\"Creating early warning alerts...\")\n",
    "\n",
    "def generate_alerts(predictions, threshold_confidence=0.7):\n",
    "    \"\"\"\n",
    "    Generate alerts for high-risk farms\n",
    "    \"\"\"\n",
    "    alerts = []\n",
    "    \n",
    "    # High-risk diseased farms\n",
    "    high_risk_farms = predictions[\n",
    "        (predictions['predicted_disease'] != 'Healthy') & \n",
    "        (predictions['confidence'] >= threshold_confidence)\n",
    "    ]\n",
    "    \n",
    "    for _, farm in high_risk_farms.iterrows():\n",
    "        alert = {\n",
    "            'alert_id': f\"ALERT_{farm['farm_id']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "            'farm_id': farm['farm_id'],\n",
    "            'lat': farm['lat'],\n",
    "            'lon': farm['lon'],\n",
    "            'crop_type': farm['crop_type'],\n",
    "            'predicted_disease': farm['predicted_disease'],\n",
    "            'confidence': farm['confidence'],\n",
    "            'risk_level': farm['risk_level'],\n",
    "            'alert_type': 'Disease Detection',\n",
    "            'priority': 'High' if farm['confidence'] > 0.8 else 'Medium',\n",
    "            'message': f\"High risk of {farm['predicted_disease']} detected at Farm {farm['farm_id']} (Confidence: {farm['confidence']:.2f})\",\n",
    "            'recommended_actions': get_recommendations(farm['predicted_disease']),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        alerts.append(alert)\n",
    "    \n",
    "    return alerts\n",
    "\n",
    "def get_recommendations(disease):\n",
    "    \"\"\"\n",
    "    Get recommended actions for each disease type\n",
    "    \"\"\"\n",
    "    recommendations = {\n",
    "        'Healthy': ['Continue regular monitoring', 'Maintain current practices'],\n",
    "        'Blight': ['Apply fungicide treatment', 'Improve drainage', 'Remove affected plants'],\n",
    "        'Rust': ['Apply rust-specific fungicide', 'Increase air circulation', 'Monitor closely'],\n",
    "        'Mosaic': ['Remove infected plants', 'Control insect vectors', 'Use resistant varieties'],\n",
    "        'Bacterial': ['Apply copper-based bactericide', 'Improve sanitation', 'Avoid overhead irrigation']\n",
    "    }\n",
    "    \n",
    "    return recommendations.get(disease, ['Consult agricultural expert', 'Monitor closely'])\n",
    "\n",
    "# Generate alerts\n",
    "alerts = generate_alerts(predictions)\n",
    "\n",
    "print(f\"✅ Generated {len(alerts)} alerts\")\n",
    "\n",
    "if alerts:\n",
    "    print(\"\\nHigh Priority Alerts:\")\n",
    "    for alert in alerts[:5]:  # Show first 5 alerts\n",
    "        print(f\"\\n🚨 {alert['alert_type']} - {alert['priority']} Priority\")\n",
    "        print(f\"   Farm: {alert['farm_id']} ({alert['crop_type']})\")\n",
    "        print(f\"   Disease: {alert['predicted_disease']} (Confidence: {alert['confidence']:.2f})\")\n",
    "        print(f\"   Location: {alert['lat']:.3f}, {alert['lon']:.3f}\")\n",
    "        print(f\"   Actions: {', '.join(alert['recommended_actions'][:2])}\")\nelse:\n",
    "    print(\"\\n✅ No high-risk alerts generated - all farms appear healthy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive dashboard\n",
    "print(\"Creating interactive dashboard...\")\n",
    "\n",
    "# Create prediction map\n",
    "center_lat = farms_df['lat'].mean()\n",
    "center_lon = farms_df['lon'].mean()\n",
    "\n",
    "# Create base map\n",
    "m = folium.Map(\n",
    "    location=[center_lat, center_lon],\n",
    "    zoom_start=10,\n",
    "    tiles='OpenStreetMap'\n",
    ")\n",
    "\n",
    "# Color mapping for diseases and risk levels\n",
    "disease_colors = {\n",
    "    'Healthy': 'green',\n",
    "    'Blight': 'red',\n",
    "    'Rust': 'orange',\n",
    "    'Mosaic': 'purple',\n",
    "    'Bacterial': 'darkred'\n",
    "}\n",
    "\n",
    "risk_colors = {\n",
    "    'Low': 'green',\n",
    "    'Medium': 'orange',\n",
    "    'High': 'red'\n",
    "}\n",
    "\n",
    "# Add farm markers\n",
    "for _, pred in predictions.iterrows():\n",
    "    # Color by risk level\n",
    "    color = risk_colors.get(pred['risk_level'], 'blue')\n",
    "    \n",
    "    # Create popup with detailed information\n",
    "    popup_html = f\"\"\"\n",
    "    <div style=\"width: 200px;\">\n",
    "        <h4>Farm {pred['farm_id']}</h4>\n",
    "        <p><b>Crop:</b> {pred['crop_type']}</p>\n",
    "        <p><b>Predicted Disease:</b> {pred['predicted_disease']}</p>\n",
    "        <p><b>Confidence:</b> {pred['confidence']:.2f}</p>\n",
    "        <p><b>Risk Level:</b> {pred['risk_level']}</p>\n",
    "        <p><b>Timestamp:</b> {pred['timestamp'][:19]}</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add marker\n",
    "    folium.CircleMarker(\n",
    "        location=[pred['lat'], pred['lon']],\n",
    "        radius=8,\n",
    "        popup=folium.Popup(popup_html, max_width=250),\n",
    "        color='black',\n",
    "        fillColor=color,\n",
    "        fillOpacity=0.7,\n",
    "        weight=2\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add legend\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "            bottom: 50px; left: 50px; width: 150px; height: 120px; \n",
    "            background-color: white; border:2px solid grey; z-index:9999; \n",
    "            font-size:14px; padding: 10px\">\n",
    "<p><b>Risk Levels</b></p>\n",
    "<p><i class=\"fa fa-circle\" style=\"color:green\"></i> Low Risk</p>\n",
    "<p><i class=\"fa fa-circle\" style=\"color:orange\"></i> Medium Risk</p>\n",
    "<p><i class=\"fa fa-circle\" style=\"color:red\"></i> High Risk</p>\n",
    "</div>\n",
    "'''\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# Save dashboard map\n",
    "dashboard_path = RESULTS_DIR / '07_prediction_dashboard.html'\n",
    "m.save(str(dashboard_path))\n",
    "print(f\"✅ Interactive dashboard saved to {dashboard_path}\")\n",
    "\n",
    "# Create summary statistics\n",
    "summary_stats = {\n",
    "    'total_farms': len(predictions),\n",
    "    'healthy_farms': len(predictions[predictions['predicted_disease'] == 'Healthy']),\n",
    "    'diseased_farms': len(predictions[predictions['predicted_disease'] != 'Healthy']),\n",
    "    'high_risk_farms': len(predictions[predictions['risk_level'] == 'High']),\n",
    "    'alerts_generated': len(alerts),\n",
    "    'avg_confidence': predictions['confidence'].mean(),\n",
    "    'prediction_timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "print(\"\\n📊 Dashboard Summary:\")\n",
    "print(f\"- Total Farms: {summary_stats['total_farms']}\")\n",
    "print(f\"- Healthy Farms: {summary_stats['healthy_farms']} ({summary_stats['healthy_farms']/summary_stats['total_farms']*100:.1f}%)\")\n",
    "print(f\"- Diseased Farms: {summary_stats['diseased_farms']} ({summary_stats['diseased_farms']/summary_stats['total_farms']*100:.1f}%)\")\n",
    "print(f\"- High Risk Farms: {summary_stats['high_risk_farms']}\")\n",
    "print(f\"- Alerts Generated: {summary_stats['alerts_generated']}\")\n",
    "print(f\"- Average Confidence: {summary_stats['avg_confidence']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results for stakeholders\n",
    "print(\"Exporting results...\")\n",
    "\n",
    "# Save predictions\n",
    "predictions_file = RESULTS_DIR / '07_current_predictions.csv'\n",
    "predictions.to_csv(predictions_file, index=False)\n",
    "print(f\"✅ Predictions saved to {predictions_file}\")\n",
    "\n",
    "# Save alerts\n",
    "if alerts:\n",
    "    alerts_df = pd.DataFrame(alerts)\n",
    "    alerts_file = RESULTS_DIR / '07_current_alerts.csv'\n",
    "    alerts_df.to_csv(alerts_file, index=False)\n",
    "    print(f\"✅ Alerts saved to {alerts_file}\")\n",
    "\n",
    "# Save weather data\n",
    "weather_file = RESULTS_DIR / '07_current_weather.csv'\n",
    "current_weather.to_csv(weather_file, index=False)\n",
    "print(f\"✅ Weather data saved to {weather_file}\")\n",
    "\n",
    "# Create executive summary report\n",
    "report = f\"\"\"\n",
    "# AgroGraphNet - Daily Prediction Report\n",
    "\n",
    "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**Model:** {best_model_name} (Accuracy: {best_model_accuracy:.3f})\n",
    "\n",
    "## Summary Statistics\n",
    "\n",
    "- **Total Farms Monitored:** {summary_stats['total_farms']}\n",
    "- **Healthy Farms:** {summary_stats['healthy_farms']} ({summary_stats['healthy_farms']/summary_stats['total_farms']*100:.1f}%)\n",
    "- **Farms with Disease Risk:** {summary_stats['diseased_farms']} ({summary_stats['diseased_farms']/summary_stats['total_farms']*100:.1f}%)\n",
    "- **High Risk Farms:** {summary_stats['high_risk_farms']}\n",
    "- **Active Alerts:** {summary_stats['alerts_generated']}\n",
    "- **Average Prediction Confidence:** {summary_stats['avg_confidence']:.3f}\n",
    "\n",
    "## Disease Distribution\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for disease, count in disease_counts.items():\n",
    "    percentage = count / len(predictions) * 100\n",
    "    report += f\"- **{disease}:** {count} farms ({percentage:.1f}%)\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "\n",
    "## Risk Assessment\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for risk, count in risk_counts.items():\n",
    "    percentage = count / len(predictions) * 100\n",
    "    report += f\"- **{risk} Risk:** {count} farms ({percentage:.1f}%)\\n\"\n",
    "\n",
    "if alerts:\n",
    "    report += f\"\"\"\n",
    "\n",
    "## Active Alerts\n",
    "\n",
    "\"\"\"\n",
    "    for i, alert in enumerate(alerts[:5], 1):\n",
    "        report += f\"\"\"\n",
    "### Alert {i}: {alert['farm_id']}\n",
    "- **Disease:** {alert['predicted_disease']}\n",
    "- **Confidence:** {alert['confidence']:.2f}\n",
    "- **Priority:** {alert['priority']}\n",
    "- **Recommended Actions:** {', '.join(alert['recommended_actions'])}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "report += f\"\"\"\n",
    "\n",
    "## Files Generated\n",
    "\n",
    "- **Interactive Dashboard:** `07_prediction_dashboard.html`\n",
    "- **Detailed Predictions:** `07_current_predictions.csv`\n",
    "- **Active Alerts:** `07_current_alerts.csv`\n",
    "- **Weather Data:** `07_current_weather.csv`\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Review high-priority alerts and take recommended actions\n",
    "2. Monitor weather conditions for changes\n",
    "3. Update predictions as new data becomes available\n",
    "4. Validate predictions with field observations\n",
    "\n",
    "---\n",
    "*This report was generated automatically by the AgroGraphNet prediction pipeline.*\n",
    "\"\"\"\n",
    "\n",
    "# Save report\n",
    "report_file = RESULTS_DIR / '07_daily_report.md'\n",
    "with open(report_file, 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"✅ Executive report saved to {report_file}\")\n",
    "\n",
    "# Save summary statistics as JSON\n",
    "summary_file = RESULTS_DIR / '07_prediction_summary.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2)\n",
    "\n",
    "print(f\"✅ Summary statistics saved to {summary_file}\")\n",
    "\n",
    "print(\"\\n🎉 Prediction pipeline completed successfully!\")\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(f\"- Interactive Dashboard: {dashboard_path}\")\n",
    "print(f\"- Predictions: {predictions_file}\")\n",
    "print(f\"- Alerts: {alerts_file if alerts else 'No alerts generated'}\")\n",
    "print(f\"- Weather Data: {weather_file}\")\n",
    "print(f\"- Executive Report: {report_file}\")\n",
    "print(f\"- Summary: {summary_file}\")\n",
    "\n",
    "print(\"\\n📋 Usage Instructions:\")\n",
    "print(\"1. Open the interactive dashboard in a web browser\")\n",
    "print(\"2. Review the executive report for key insights\")\n",
    "print(\"3. Check alerts CSV for detailed action items\")\n",
    "print(\"4. Use the prediction CSV for further analysis\")\n",
    "print(\"5. Re-run this notebook with new weather data for updated predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}